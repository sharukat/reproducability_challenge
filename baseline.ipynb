{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","sys.path.append('/content/drive/MyDrive/NN_Course_Project/project')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UV3GgQ_Kaydk","executionInfo":{"status":"ok","timestamp":1681165156157,"user_tz":240,"elapsed":28008,"user":{"displayName":"Sharuka Promodya","userId":"04366359822682705905"}},"outputId":"d8f6cb70-4fca-4688-d936-25decda84a64"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"qje39BnmauCw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681165174814,"user_tz":240,"elapsed":18662,"user":{"displayName":"Sharuka Promodya","userId":"04366359822682705905"}},"outputId":"fb519b83-ac99-4d01-cc4f-18915f464884"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import os\n","import torch\n","torch.cuda.empty_cache()\n","\n","import torchvision\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","\n","from torch import nn\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","from timeit import default_timer as timer \n","\n","from lib.data import loader\n","from lib.train_test import TrainTestModel\n","from lib.helper_funcs import MetricsComputation, print_decos, load_model_opt_sch, load_trained_model, print_results\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"IEvOCvO1auCy"},"source":["# CIFAR-10 Dataset"]},{"cell_type":"markdown","source":["### VGG Model"],"metadata":{"id":"LTOqQmzPpozR"}},{"cell_type":"code","source":["# dataloaders for datasets\n","dataloader_train, dataloader_test = loader('CIFAR10')\n","VGG_C10, optimizer, scheduler = load_model_opt_sch('vgg16', num_classes=10)"],"metadata":{"id":"EKBfPyyypq6r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680565464245,"user_tz":240,"elapsed":6578,"user":{"displayName":"Sharuka Promodya","userId":"04366359822682705905"}},"outputId":"3c6a4538-6ae0-431b-c85c-69dadd9a0c41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Length of train dataloader: 391 batches of 128\n","Length of test dataloader: 79 batches of 128\n"]}]},{"cell_type":"markdown","source":["#### Training"],"metadata":{"id":"guHjT9F2OsKw"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["fbe14ee5fd104e73b2cfec9ce3d4b6b0","d52ed8b855c348ba918168949673ae8a","604ac3f2d24946bf9ccd82d42ae4a880","62ab785b88a54be5a33e112d0e50a66e","e34d2d3845c04618a53bf386d5ab320d","af69d184f48c45b5ae0ceea58c2a9961","a5dc66de2843448282ecb8d6114a1da7","2e3a5365f2034d7bbc183cf8d6608f05","2aba127deac94805b044991b2757ecc8","7175af3b6c8b408582531aafafe752fb","99c87cc35008418590a46d0a8566a48e"]},"id":"zGZrfIK4auC7","outputId":"56ea3346-137f-40cb-ea90-bf6c830a0f11","executionInfo":{"status":"ok","timestamp":1680573897281,"user_tz":240,"elapsed":8432288,"user":{"displayName":"Sharuka Promodya","userId":"04366359822682705905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["========================================\n","TRAINING INITIATED\n","========================================\n","\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbe14ee5fd104e73b2cfec9ce3d4b6b0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 1 | train_loss: 2.0378 | train_acc: 17.4393% | \n","Epoch: 2 | train_loss: 1.9033 | train_acc: 20.1403% | \n","Epoch: 3 | train_loss: 1.8882 | train_acc: 20.7289% | \n","Epoch: 4 | train_loss: 1.8782 | train_acc: 20.8800% | \n","Epoch: 5 | train_loss: 1.8682 | train_acc: 21.5513% | \n","Epoch: 6 | train_loss: 1.8593 | train_acc: 22.2287% | \n","Epoch: 7 | train_loss: 1.8502 | train_acc: 23.0902% | \n","Epoch: 8 | train_loss: 1.8422 | train_acc: 23.2369% | \n","Epoch: 9 | train_loss: 1.8267 | train_acc: 24.2311% | \n","Epoch: 10 | train_loss: 1.8136 | train_acc: 24.6587% | \n","Epoch: 11 | train_loss: 1.7969 | train_acc: 25.4843% | \n","Epoch: 12 | train_loss: 1.7822 | train_acc: 26.3091% | \n","Epoch: 13 | train_loss: 1.7656 | train_acc: 27.1316% | \n","Epoch: 14 | train_loss: 1.7510 | train_acc: 27.5156% | \n","Epoch: 15 | train_loss: 1.7337 | train_acc: 28.2009% | \n","Epoch: 16 | train_loss: 1.7191 | train_acc: 28.6333% | \n","Epoch: 17 | train_loss: 1.7050 | train_acc: 29.5864% | \n","Epoch: 18 | train_loss: 1.6938 | train_acc: 29.9465% | \n","Epoch: 19 | train_loss: 1.6806 | train_acc: 30.9922% | \n","Epoch: 20 | train_loss: 1.6691 | train_acc: 31.5257% | \n","Epoch: 21 | train_loss: 1.6570 | train_acc: 32.2678% | \n","Epoch: 22 | train_loss: 1.6455 | train_acc: 32.9244% | \n","Epoch: 23 | train_loss: 1.6334 | train_acc: 33.9670% | \n","Epoch: 24 | train_loss: 1.6165 | train_acc: 34.8046% | \n","Epoch: 25 | train_loss: 1.6094 | train_acc: 35.0132% | \n","Epoch: 26 | train_loss: 1.5946 | train_acc: 35.7393% | \n","Epoch: 27 | train_loss: 1.5837 | train_acc: 36.3183% | \n","Epoch: 28 | train_loss: 1.5696 | train_acc: 36.9909% | \n","Epoch: 29 | train_loss: 1.5646 | train_acc: 37.3601% | \n","Epoch: 30 | train_loss: 1.5508 | train_acc: 38.1917% | \n","Epoch: 31 | train_loss: 1.5386 | train_acc: 38.6545% | \n","Epoch: 32 | train_loss: 1.5295 | train_acc: 39.4062% | \n","Epoch: 33 | train_loss: 1.5200 | train_acc: 39.5440% | \n","Epoch: 34 | train_loss: 1.5042 | train_acc: 40.7081% | \n","Epoch: 35 | train_loss: 1.4911 | train_acc: 41.1081% | \n","Epoch: 36 | train_loss: 1.4824 | train_acc: 41.7823% | \n","Epoch: 37 | train_loss: 1.4752 | train_acc: 42.4317% | \n","Epoch: 38 | train_loss: 1.4625 | train_acc: 43.2065% | \n","Epoch: 39 | train_loss: 1.4508 | train_acc: 43.9430% | \n","Epoch: 40 | train_loss: 1.4404 | train_acc: 44.0161% | \n","Epoch: 41 | train_loss: 1.4297 | train_acc: 44.6703% | \n","Epoch: 42 | train_loss: 1.4231 | train_acc: 45.1367% | \n","Epoch: 43 | train_loss: 1.4107 | train_acc: 45.4624% | \n","Epoch: 44 | train_loss: 1.4016 | train_acc: 45.7029% | \n","Epoch: 45 | train_loss: 1.3921 | train_acc: 46.6500% | \n","Epoch: 46 | train_loss: 1.3784 | train_acc: 46.9345% | \n","Epoch: 47 | train_loss: 1.3747 | train_acc: 47.2598% | \n","Epoch: 48 | train_loss: 1.3611 | train_acc: 47.7494% | \n","Epoch: 49 | train_loss: 1.3501 | train_acc: 48.0687% | \n","Epoch: 50 | train_loss: 1.3435 | train_acc: 48.8287% | \n","\n","===== Checkpoint saved at epoch 50 =====\n","Epoch: 51 | train_loss: 1.3329 | train_acc: 49.1324% | \n","Epoch: 52 | train_loss: 1.3223 | train_acc: 49.6431% | \n","Epoch: 53 | train_loss: 1.3085 | train_acc: 50.2486% | \n","Epoch: 54 | train_loss: 1.3047 | train_acc: 50.6913% | \n","Epoch: 55 | train_loss: 1.2934 | train_acc: 51.0670% | \n","Epoch: 56 | train_loss: 1.2824 | train_acc: 51.6796% | \n","Epoch: 57 | train_loss: 1.2722 | train_acc: 52.1927% | \n","Epoch: 58 | train_loss: 1.2670 | train_acc: 52.4784% | \n","Epoch: 59 | train_loss: 1.2569 | train_acc: 52.8976% | \n","Epoch: 60 | train_loss: 1.2469 | train_acc: 53.1758% | \n","Epoch: 61 | train_loss: 1.2371 | train_acc: 53.7424% | \n","Epoch: 62 | train_loss: 1.2270 | train_acc: 54.2787% | \n","Epoch: 63 | train_loss: 1.2244 | train_acc: 53.9622% | \n","Epoch: 64 | train_loss: 1.2060 | train_acc: 55.1830% | \n","Epoch: 65 | train_loss: 1.2036 | train_acc: 54.9540% | \n","Epoch: 66 | train_loss: 1.1907 | train_acc: 55.9507% | \n","Epoch: 67 | train_loss: 1.1864 | train_acc: 56.0798% | \n","Epoch: 68 | train_loss: 1.1726 | train_acc: 56.5221% | \n","Epoch: 69 | train_loss: 1.1608 | train_acc: 56.9417% | \n","Epoch: 70 | train_loss: 1.1539 | train_acc: 57.2762% | \n","Epoch: 71 | train_loss: 1.1448 | train_acc: 57.6415% | \n","Epoch: 72 | train_loss: 1.1380 | train_acc: 57.8493% | \n","Epoch: 73 | train_loss: 1.1291 | train_acc: 58.2197% | \n","Epoch: 74 | train_loss: 1.1222 | train_acc: 58.6441% | \n","Epoch: 75 | train_loss: 1.1122 | train_acc: 58.9454% | \n","Epoch: 76 | train_loss: 1.1041 | train_acc: 59.1884% | \n","Epoch: 77 | train_loss: 1.0897 | train_acc: 59.9964% | \n","Epoch: 78 | train_loss: 1.0865 | train_acc: 60.1914% | \n","Epoch: 79 | train_loss: 1.0790 | train_acc: 60.1383% | \n","Epoch: 80 | train_loss: 1.0669 | train_acc: 60.8120% | \n","Epoch: 81 | train_loss: 1.0588 | train_acc: 61.1937% | \n","Epoch: 82 | train_loss: 1.0510 | train_acc: 61.4434% | \n","Epoch: 83 | train_loss: 1.0463 | train_acc: 61.3955% | \n","Epoch: 84 | train_loss: 1.0348 | train_acc: 62.2906% | \n","Epoch: 85 | train_loss: 1.0306 | train_acc: 62.0265% | \n","Epoch: 86 | train_loss: 1.0153 | train_acc: 62.7286% | \n","Epoch: 87 | train_loss: 1.0136 | train_acc: 63.0267% | \n","Epoch: 88 | train_loss: 1.0003 | train_acc: 63.5882% | \n","Epoch: 89 | train_loss: 0.9968 | train_acc: 63.6349% | \n","Epoch: 90 | train_loss: 0.9886 | train_acc: 64.0209% | \n","Epoch: 91 | train_loss: 0.9850 | train_acc: 64.1376% | \n","Epoch: 92 | train_loss: 0.9710 | train_acc: 64.6675% | \n","Epoch: 93 | train_loss: 0.9667 | train_acc: 64.8981% | \n","Epoch: 94 | train_loss: 0.9648 | train_acc: 64.9177% | \n","Epoch: 95 | train_loss: 0.9556 | train_acc: 65.3289% | \n","Epoch: 96 | train_loss: 0.9462 | train_acc: 65.7761% | \n","Epoch: 97 | train_loss: 0.9416 | train_acc: 65.8931% | \n","Epoch: 98 | train_loss: 0.9354 | train_acc: 65.8867% | \n","Epoch: 99 | train_loss: 0.9269 | train_acc: 66.2640% | \n","Epoch: 100 | train_loss: 0.9178 | train_acc: 66.7867% | \n","\n","===== Checkpoint saved at epoch 100 =====\n","Epoch: 101 | train_loss: 0.9132 | train_acc: 66.8886% | \n","Epoch: 102 | train_loss: 0.9075 | train_acc: 67.2614% | \n","Epoch: 103 | train_loss: 0.9079 | train_acc: 67.1475% | \n","Epoch: 104 | train_loss: 0.8990 | train_acc: 67.6171% | \n","Epoch: 105 | train_loss: 0.8945 | train_acc: 67.6287% | \n","Epoch: 106 | train_loss: 0.8864 | train_acc: 67.7949% | \n","Epoch: 107 | train_loss: 0.8769 | train_acc: 68.4891% | \n","Epoch: 108 | train_loss: 0.8685 | train_acc: 68.6017% | \n","Epoch: 109 | train_loss: 0.8700 | train_acc: 68.7596% | \n","Epoch: 110 | train_loss: 0.8617 | train_acc: 68.9518% | \n","Epoch: 111 | train_loss: 0.8582 | train_acc: 69.1884% | \n","Epoch: 112 | train_loss: 0.8511 | train_acc: 69.3207% | \n","Epoch: 113 | train_loss: 0.8491 | train_acc: 69.5704% | \n","Epoch: 114 | train_loss: 0.8427 | train_acc: 69.7814% | \n","Epoch: 115 | train_loss: 0.8349 | train_acc: 69.9700% | \n","Epoch: 116 | train_loss: 0.8303 | train_acc: 70.2146% | \n","Epoch: 117 | train_loss: 0.8280 | train_acc: 70.1830% | \n","Epoch: 118 | train_loss: 0.8134 | train_acc: 70.8863% | \n","Epoch: 119 | train_loss: 0.8173 | train_acc: 70.7613% | \n","Epoch: 120 | train_loss: 0.8085 | train_acc: 71.0018% | \n","Epoch: 121 | train_loss: 0.8026 | train_acc: 71.3931% | \n","Epoch: 122 | train_loss: 0.7972 | train_acc: 71.4442% | \n","Epoch: 123 | train_loss: 0.7977 | train_acc: 71.7243% | \n","Epoch: 124 | train_loss: 0.7942 | train_acc: 71.4362% | \n","Epoch: 125 | train_loss: 0.7885 | train_acc: 71.7463% | \n","Epoch: 126 | train_loss: 0.7845 | train_acc: 72.0652% | \n","Epoch: 127 | train_loss: 0.7796 | train_acc: 72.0976% | \n","Epoch: 128 | train_loss: 0.7777 | train_acc: 72.3258% | \n","Epoch: 129 | train_loss: 0.7681 | train_acc: 72.5943% | \n","Epoch: 130 | train_loss: 0.7665 | train_acc: 72.9608% | \n","Epoch: 131 | train_loss: 0.7577 | train_acc: 72.9799% | \n","Epoch: 132 | train_loss: 0.7533 | train_acc: 73.1638% | \n","Epoch: 133 | train_loss: 0.7484 | train_acc: 73.3987% | \n","Epoch: 134 | train_loss: 0.7471 | train_acc: 73.4539% | \n","Epoch: 135 | train_loss: 0.7426 | train_acc: 73.6793% | \n","Epoch: 136 | train_loss: 0.7359 | train_acc: 73.7884% | \n","Epoch: 137 | train_loss: 0.7370 | train_acc: 73.7740% | \n","Epoch: 138 | train_loss: 0.7266 | train_acc: 74.1892% | \n","Epoch: 139 | train_loss: 0.7282 | train_acc: 74.1840% | \n","Epoch: 140 | train_loss: 0.7235 | train_acc: 74.3183% | \n","Epoch: 141 | train_loss: 0.7183 | train_acc: 74.7155% | \n","Epoch: 142 | train_loss: 0.7118 | train_acc: 74.8693% | \n","Epoch: 143 | train_loss: 0.7119 | train_acc: 74.7670% | \n","Epoch: 144 | train_loss: 0.7052 | train_acc: 75.0332% | \n","Epoch: 145 | train_loss: 0.7050 | train_acc: 75.1806% | \n","Epoch: 146 | train_loss: 0.6977 | train_acc: 75.3073% | \n","Epoch: 147 | train_loss: 0.6994 | train_acc: 75.2685% | \n","Epoch: 148 | train_loss: 0.6922 | train_acc: 75.7321% | \n","Epoch: 149 | train_loss: 0.6885 | train_acc: 75.6997% | \n","Epoch: 150 | train_loss: 0.6848 | train_acc: 75.8672% | \n","\n","===== Checkpoint saved at epoch 150 =====\n","Epoch: 151 | train_loss: 0.6811 | train_acc: 75.9303% | \n","Epoch: 152 | train_loss: 0.6785 | train_acc: 76.1941% | \n","Epoch: 153 | train_loss: 0.6734 | train_acc: 76.4458% | \n","Epoch: 154 | train_loss: 0.6702 | train_acc: 76.3499% | \n","Epoch: 155 | train_loss: 0.6680 | train_acc: 76.3439% | \n","Epoch: 156 | train_loss: 0.6600 | train_acc: 76.7032% | \n","Epoch: 157 | train_loss: 0.6573 | train_acc: 76.8998% | \n","Epoch: 158 | train_loss: 0.6537 | train_acc: 76.8554% | \n","Epoch: 159 | train_loss: 0.6529 | train_acc: 77.1116% | \n","Epoch: 160 | train_loss: 0.6512 | train_acc: 77.1695% | \n","Epoch: 161 | train_loss: 0.6480 | train_acc: 77.3426% | \n","Epoch: 162 | train_loss: 0.6417 | train_acc: 77.5292% | \n","Epoch: 163 | train_loss: 0.6403 | train_acc: 77.5803% | \n","Epoch: 164 | train_loss: 0.6374 | train_acc: 77.6343% | \n","Epoch: 165 | train_loss: 0.6336 | train_acc: 77.6630% | \n","Epoch: 166 | train_loss: 0.6299 | train_acc: 77.8321% | \n","Epoch: 167 | train_loss: 0.6229 | train_acc: 78.1170% | \n","Epoch: 168 | train_loss: 0.6226 | train_acc: 78.2365% | \n","Epoch: 169 | train_loss: 0.6229 | train_acc: 78.1542% | \n","Epoch: 170 | train_loss: 0.6144 | train_acc: 78.5326% | \n","Epoch: 171 | train_loss: 0.6180 | train_acc: 78.4731% | \n","Epoch: 172 | train_loss: 0.6104 | train_acc: 78.7316% | \n","Epoch: 173 | train_loss: 0.6098 | train_acc: 78.8363% | \n","Epoch: 174 | train_loss: 0.6059 | train_acc: 78.7716% | \n","Epoch: 175 | train_loss: 0.6032 | train_acc: 78.9786% | \n","Epoch: 176 | train_loss: 0.5990 | train_acc: 79.1025% | \n","Epoch: 177 | train_loss: 0.6014 | train_acc: 78.9794% | \n","Epoch: 178 | train_loss: 0.5925 | train_acc: 79.3298% | \n","Epoch: 179 | train_loss: 0.5894 | train_acc: 79.4046% | \n","Epoch: 180 | train_loss: 0.5821 | train_acc: 79.7470% | \n","Epoch: 181 | train_loss: 0.5857 | train_acc: 79.4881% | \n","Epoch: 182 | train_loss: 0.5834 | train_acc: 79.6511% | \n","Epoch: 183 | train_loss: 0.5794 | train_acc: 79.9305% | \n","Epoch: 184 | train_loss: 0.5738 | train_acc: 80.0236% | \n","Epoch: 185 | train_loss: 0.5715 | train_acc: 80.2506% | \n","Epoch: 186 | train_loss: 0.5722 | train_acc: 80.0312% | \n","Epoch: 187 | train_loss: 0.5673 | train_acc: 80.2777% | \n","Epoch: 188 | train_loss: 0.5645 | train_acc: 80.4875% | \n","Epoch: 189 | train_loss: 0.5631 | train_acc: 80.4152% | \n","Epoch: 190 | train_loss: 0.5592 | train_acc: 80.6242% | \n","Epoch: 191 | train_loss: 0.5529 | train_acc: 80.6797% | \n","Epoch: 192 | train_loss: 0.5540 | train_acc: 80.9259% | \n","Epoch: 193 | train_loss: 0.5578 | train_acc: 80.6857% | \n","Epoch: 194 | train_loss: 0.5450 | train_acc: 80.9579% | \n","Epoch: 195 | train_loss: 0.5459 | train_acc: 80.9443% | \n","Epoch: 196 | train_loss: 0.5455 | train_acc: 80.9699% | \n","Epoch: 197 | train_loss: 0.5386 | train_acc: 81.3639% | \n","Epoch: 198 | train_loss: 0.5397 | train_acc: 81.4474% | \n","Epoch: 199 | train_loss: 0.5399 | train_acc: 81.2700% | \n","Epoch: 200 | train_loss: 0.5335 | train_acc: 81.5141% | \n","\n","===== Checkpoint saved at epoch 200 =====\n","Epoch: 201 | train_loss: 0.5262 | train_acc: 81.8039% | \n","Epoch: 202 | train_loss: 0.5260 | train_acc: 81.7879% | \n","Epoch: 203 | train_loss: 0.5200 | train_acc: 82.0029% | \n","Epoch: 204 | train_loss: 0.5202 | train_acc: 82.0105% | \n","Epoch: 205 | train_loss: 0.5173 | train_acc: 82.1268% | \n","Epoch: 206 | train_loss: 0.5148 | train_acc: 82.1943% | \n","Epoch: 207 | train_loss: 0.5098 | train_acc: 82.4516% | \n","Epoch: 208 | train_loss: 0.5085 | train_acc: 82.4608% | \n","Epoch: 209 | train_loss: 0.5077 | train_acc: 82.4129% | \n","Epoch: 210 | train_loss: 0.5064 | train_acc: 82.5252% | \n","Epoch: 211 | train_loss: 0.5010 | train_acc: 82.6055% | \n","Epoch: 212 | train_loss: 0.5056 | train_acc: 82.6918% | \n","Epoch: 213 | train_loss: 0.4970 | train_acc: 82.9672% | \n","Epoch: 214 | train_loss: 0.4965 | train_acc: 82.8724% | \n","Epoch: 215 | train_loss: 0.4948 | train_acc: 82.9120% | \n","Epoch: 216 | train_loss: 0.4955 | train_acc: 82.9640% | \n","Epoch: 217 | train_loss: 0.4850 | train_acc: 83.1706% | \n","Epoch: 218 | train_loss: 0.4846 | train_acc: 83.2357% | \n","Epoch: 219 | train_loss: 0.4838 | train_acc: 83.2968% | \n","Epoch: 220 | train_loss: 0.4859 | train_acc: 83.3844% | \n","Epoch: 221 | train_loss: 0.4758 | train_acc: 83.6225% | \n","Epoch: 222 | train_loss: 0.4765 | train_acc: 83.4495% | \n","Epoch: 223 | train_loss: 0.4741 | train_acc: 83.5142% | \n","Epoch: 224 | train_loss: 0.4765 | train_acc: 83.5846% | \n","Epoch: 225 | train_loss: 0.4725 | train_acc: 83.6797% | \n","Epoch: 226 | train_loss: 0.4623 | train_acc: 83.9866% | \n","Epoch: 227 | train_loss: 0.4634 | train_acc: 84.0022% | \n","Epoch: 228 | train_loss: 0.4633 | train_acc: 84.0845% | \n","Epoch: 229 | train_loss: 0.4588 | train_acc: 84.1540% | \n","Epoch: 230 | train_loss: 0.4580 | train_acc: 84.2707% | \n","Epoch: 231 | train_loss: 0.4566 | train_acc: 84.1952% | \n","Epoch: 232 | train_loss: 0.4555 | train_acc: 84.3574% | \n","Epoch: 233 | train_loss: 0.4561 | train_acc: 84.4465% | \n","Epoch: 234 | train_loss: 0.4480 | train_acc: 84.5788% | \n","Epoch: 235 | train_loss: 0.4489 | train_acc: 84.5912% | \n","Epoch: 236 | train_loss: 0.4496 | train_acc: 84.3826% | \n","Epoch: 237 | train_loss: 0.4499 | train_acc: 84.5868% | \n","Epoch: 238 | train_loss: 0.4454 | train_acc: 84.8489% | \n","Epoch: 239 | train_loss: 0.4439 | train_acc: 84.8090% | \n","Epoch: 240 | train_loss: 0.4388 | train_acc: 84.6863% | \n","Epoch: 241 | train_loss: 0.4378 | train_acc: 84.9469% | \n","Epoch: 242 | train_loss: 0.4346 | train_acc: 85.0052% | \n","Epoch: 243 | train_loss: 0.4310 | train_acc: 85.3109% | \n","Epoch: 244 | train_loss: 0.4323 | train_acc: 85.1387% | \n","Epoch: 245 | train_loss: 0.4261 | train_acc: 85.3165% | \n","Epoch: 246 | train_loss: 0.4265 | train_acc: 85.4104% | \n","Epoch: 247 | train_loss: 0.4285 | train_acc: 85.3824% | \n","Epoch: 248 | train_loss: 0.4194 | train_acc: 85.6758% | \n","Epoch: 249 | train_loss: 0.4216 | train_acc: 85.5543% | \n","Epoch: 250 | train_loss: 0.4177 | train_acc: 85.6694% | \n","Epoch: 251 | train_loss: 0.4178 | train_acc: 85.7093% | \n","Epoch: 252 | train_loss: 0.4159 | train_acc: 85.7493% | \n","Epoch: 253 | train_loss: 0.4063 | train_acc: 85.9887% | \n","Epoch: 254 | train_loss: 0.4134 | train_acc: 85.8680% | \n","Epoch: 255 | train_loss: 0.4114 | train_acc: 85.8911% | \n","Epoch: 256 | train_loss: 0.4066 | train_acc: 86.0578% | \n","Epoch: 257 | train_loss: 0.4079 | train_acc: 86.0274% | \n","Epoch: 258 | train_loss: 0.4036 | train_acc: 86.0914% | \n","Epoch: 259 | train_loss: 0.4007 | train_acc: 86.1821% | \n","Epoch: 260 | train_loss: 0.3970 | train_acc: 86.4766% | \n","Epoch: 261 | train_loss: 0.3960 | train_acc: 86.3455% | \n","Epoch: 262 | train_loss: 0.3967 | train_acc: 86.1601% | \n","Epoch: 263 | train_loss: 0.3917 | train_acc: 86.6224% | \n","Epoch: 264 | train_loss: 0.3951 | train_acc: 86.4762% | \n","Epoch: 265 | train_loss: 0.3914 | train_acc: 86.4970% | \n","Epoch: 266 | train_loss: 0.3839 | train_acc: 86.8898% | \n","Epoch: 267 | train_loss: 0.3878 | train_acc: 86.7607% | \n","Epoch: 268 | train_loss: 0.3844 | train_acc: 86.8127% | \n","Epoch: 269 | train_loss: 0.3794 | train_acc: 87.0053% | \n","Epoch: 270 | train_loss: 0.3794 | train_acc: 87.0820% | \n","Epoch: 271 | train_loss: 0.3759 | train_acc: 87.1479% | \n","Epoch: 272 | train_loss: 0.3725 | train_acc: 87.1839% | \n","Epoch: 273 | train_loss: 0.3697 | train_acc: 87.2450% | \n","Epoch: 274 | train_loss: 0.3700 | train_acc: 87.2870% | \n","Epoch: 275 | train_loss: 0.3691 | train_acc: 87.3693% | \n","Epoch: 276 | train_loss: 0.3651 | train_acc: 87.3581% | \n","Epoch: 277 | train_loss: 0.3678 | train_acc: 87.5056% | \n","Epoch: 278 | train_loss: 0.3617 | train_acc: 87.5376% | \n","Epoch: 279 | train_loss: 0.3631 | train_acc: 87.5072% | \n","Epoch: 280 | train_loss: 0.3585 | train_acc: 87.6451% | \n","Epoch: 281 | train_loss: 0.3559 | train_acc: 87.8013% | \n","Epoch: 282 | train_loss: 0.3586 | train_acc: 87.7801% | \n","Epoch: 283 | train_loss: 0.3597 | train_acc: 87.8141% | \n","Epoch: 284 | train_loss: 0.3511 | train_acc: 87.9412% | \n","Epoch: 285 | train_loss: 0.3550 | train_acc: 87.9112% | \n","Epoch: 286 | train_loss: 0.3500 | train_acc: 88.0635% | \n","Epoch: 287 | train_loss: 0.3539 | train_acc: 88.0007% | \n","Epoch: 288 | train_loss: 0.3496 | train_acc: 88.0375% | \n","Epoch: 289 | train_loss: 0.3479 | train_acc: 88.0886% | \n","Epoch: 290 | train_loss: 0.3427 | train_acc: 88.3492% | \n","Epoch: 291 | train_loss: 0.3417 | train_acc: 88.3272% | \n","Epoch: 292 | train_loss: 0.3443 | train_acc: 88.3188% | \n","Epoch: 293 | train_loss: 0.3405 | train_acc: 88.3887% | \n","Epoch: 294 | train_loss: 0.3350 | train_acc: 88.5934% | \n","Epoch: 295 | train_loss: 0.3337 | train_acc: 88.5106% | \n","Epoch: 296 | train_loss: 0.3331 | train_acc: 88.6797% | \n","Epoch: 297 | train_loss: 0.3390 | train_acc: 88.5082% | \n","Epoch: 298 | train_loss: 0.3336 | train_acc: 88.5390% | \n","Epoch: 299 | train_loss: 0.3243 | train_acc: 88.8843% | \n","Epoch: 300 | train_loss: 0.3271 | train_acc: 88.7732% | \n","Total training time: 8431.861 seconds\n"]}],"source":["print_decos('train')\n","start_time = timer()\n","\n","VGG = TrainTestModel()\n","\n","# Training from the begining\n","VGG.train(model=VGG_C10, model_name='vgg16', dataset='cifar10', \n","          train_dataloader=dataloader_train, optimizer=optimizer,\n","          scheduler=scheduler, epochs=300, device=device) \n","\n","end_time = timer()\n","print(f\"Total training time: {end_time-start_time:.3f} seconds\")"]},{"cell_type":"markdown","source":["#### Testing"],"metadata":{"id":"t1ygA7lxTggP"}},{"cell_type":"code","source":["# dataloaders for datasets\n","dataloader_train, dataloader_test = loader('CIFAR10')\n","VGG_C10 = load_trained_model('vgg16', 'cifar10', num_classes=10)\n","VGG = TrainTestModel()"],"metadata":{"id":"Pm89B-34hN1_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_decos('eval')\n","\n","test_results = VGG.test(model=VGG_C10, dataloader=dataloader_test, \n","                        loss_fn=torch.nn.CrossEntropyLoss(), device=device)\n","\n","VGG_C10_Metrics = MetricsComputation(test_results)\n","aurc, eaurc, fpr_in_tpr_95, pr_auc = VGG_C10_Metrics.compute_metrics()\n","print_results(test_results[1], aurc, eaurc, pr_auc, fpr_in_tpr_95)"],"metadata":{"id":"iX84j_Z3O82W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680573976989,"user_tz":240,"elapsed":3501,"user":{"displayName":"Sharuka Promodya","userId":"04366359822682705905"}},"outputId":"d326a356-7221-4dcc-8425-7375fe198368"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","========================================\n","EVALUATION RESULTS\n","========================================\n","\n","Test Accuracy: 82.1301424050633\n","Area Under Risk Curve (AURC): 0.9313802083333333\n","Excessive-AURC (E-AURC): 0.912587192215657\n","Area Under Precision-Recall Curve (AUPR): 0.9693764156048593\n","False Positive Rate (FPR) at 95% True Positive Rate (TPR): 0.6366181410974244\n","\n"]}]},{"cell_type":"markdown","source":["## ResNet Model"],"metadata":{"id":"mkW3h3XMha-7"}},{"cell_type":"markdown","source":["#### Training"],"metadata":{"id":"K6HZ8HNIhm4F"}},{"cell_type":"code","source":["# dataloaders for datasets\n","dataloader_train, dataloader_test = loader('CIFAR10')\n","Resnet_C10, optimizer, scheduler = load_model_opt_sch('resnet', num_classes=10)\n","ResNet = TrainTestModel()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xo1GMBk6hZ2I","executionInfo":{"status":"ok","timestamp":1681165190736,"user_tz":240,"elapsed":15927,"user":{"displayName":"Sharuka Promodya","userId":"04366359822682705905"}},"outputId":"55ac54ac-c68c-4a19-cbdc-7c25abd10e5d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Length of train dataloader: 391 batches of 128\n","Length of test dataloader: 79 batches of 128\n"]}]},{"cell_type":"code","source":["print_decos('train')\n","start_time = timer()\n","\n","# Training from the begining\n","ResNet.train(model=Resnet_C10, model_name='resnet', dataset='cifar10', \n","          train_dataloader=dataloader_train, optimizer=optimizer,\n","          scheduler=scheduler, epochs=300, device=device) \n","\n","end_time = timer()\n","print(f\"Total training time: {end_time-start_time:.3f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e94aad9f0f5d46a6949345acd3d82f76","783266d22d53406f99e5ed34ba466803","72cd8935f5aa453780424235c37e6c47","10f157a48fbb42a3a2ac674dee40861d","4c823dbdde1c461d9489c2b04956c2f2","ac7cd2ac36c048d5b38dd1a4fe66aa3d","060caeb4ac0f4008907170511c40bc33","bcb6e5a626e8419cb4002e1007b02454","8943160977e443da9fc2021b8a241967","62bee85c04254ee8b8ff04f4a2e06a9a","3e922a6884114aba95f40a7ac5158d2b"]},"id":"sJnN4nJKhtEJ","outputId":"e59c79a1-85c1-4d84-ae01-d4b23d083952"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["========================================\n","TRAINING INITIATED\n","========================================\n","\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e94aad9f0f5d46a6949345acd3d82f76"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 1 | train_loss: 1.8956 | train_acc: 27.5436% | \n","Epoch: 2 | train_loss: 1.7889 | train_acc: 31.8522% | \n","Epoch: 3 | train_loss: 1.7817 | train_acc: 31.9218% | \n","Epoch: 4 | train_loss: 1.7738 | train_acc: 32.2498% | \n","Epoch: 5 | train_loss: 1.7661 | train_acc: 32.8081% | \n","Epoch: 6 | train_loss: 1.7598 | train_acc: 32.9664% | \n","Epoch: 7 | train_loss: 1.7536 | train_acc: 32.9332% | \n","Epoch: 8 | train_loss: 1.7454 | train_acc: 33.0966% | \n","Epoch: 9 | train_loss: 1.7363 | train_acc: 33.4475% | \n","Epoch: 10 | train_loss: 1.7291 | train_acc: 33.8167% | \n","Epoch: 11 | train_loss: 1.7209 | train_acc: 34.1308% | \n","Epoch: 12 | train_loss: 1.7172 | train_acc: 34.1272% | \n","Epoch: 13 | train_loss: 1.7080 | train_acc: 34.2959% | \n","Epoch: 14 | train_loss: 1.7029 | train_acc: 34.6755% | \n","Epoch: 15 | train_loss: 1.6964 | train_acc: 34.9864% | \n","Epoch: 16 | train_loss: 1.6901 | train_acc: 35.1471% | \n","Epoch: 17 | train_loss: 1.6835 | train_acc: 35.3441% | \n","Epoch: 18 | train_loss: 1.6779 | train_acc: 35.6837% | \n","Epoch: 19 | train_loss: 1.6702 | train_acc: 36.0078% | \n","Epoch: 20 | train_loss: 1.6632 | train_acc: 36.2152% | \n","Epoch: 21 | train_loss: 1.6578 | train_acc: 36.3411% | \n","Epoch: 22 | train_loss: 1.6524 | train_acc: 36.5357% | \n","Epoch: 23 | train_loss: 1.6462 | train_acc: 36.9453% | \n","Epoch: 24 | train_loss: 1.6415 | train_acc: 36.8766% | \n","Epoch: 25 | train_loss: 1.6327 | train_acc: 37.2994% | \n","Epoch: 26 | train_loss: 1.6256 | train_acc: 37.6475% | \n","Epoch: 27 | train_loss: 1.6226 | train_acc: 37.6555% | \n","Epoch: 28 | train_loss: 1.6154 | train_acc: 38.1206% | \n","Epoch: 29 | train_loss: 1.6101 | train_acc: 38.2121% | \n","Epoch: 30 | train_loss: 1.6048 | train_acc: 38.6337% | \n","Epoch: 31 | train_loss: 1.6002 | train_acc: 38.5774% | \n","Epoch: 32 | train_loss: 1.5968 | train_acc: 38.8887% | \n","Epoch: 33 | train_loss: 1.5918 | train_acc: 38.8155% | \n","Epoch: 34 | train_loss: 1.5859 | train_acc: 39.1752% | \n","Epoch: 35 | train_loss: 1.5818 | train_acc: 39.4921% | \n","Epoch: 36 | train_loss: 1.5750 | train_acc: 39.5380% | \n","Epoch: 37 | train_loss: 1.5708 | train_acc: 39.9437% | \n","Epoch: 38 | train_loss: 1.5643 | train_acc: 40.2693% | \n","Epoch: 39 | train_loss: 1.5615 | train_acc: 40.3964% | \n","Epoch: 40 | train_loss: 1.5562 | train_acc: 40.6198% | \n","Epoch: 41 | train_loss: 1.5500 | train_acc: 40.9483% | \n","Epoch: 42 | train_loss: 1.5475 | train_acc: 40.8760% | \n","Epoch: 43 | train_loss: 1.5413 | train_acc: 41.4402% | \n","Epoch: 44 | train_loss: 1.5384 | train_acc: 41.5006% | \n","Epoch: 45 | train_loss: 1.5321 | train_acc: 41.7543% | \n","Epoch: 46 | train_loss: 1.5281 | train_acc: 42.2055% | \n","Epoch: 47 | train_loss: 1.5227 | train_acc: 42.2762% | \n","Epoch: 48 | train_loss: 1.5189 | train_acc: 42.4516% | \n","Epoch: 49 | train_loss: 1.5145 | train_acc: 42.7078% | \n","Epoch: 50 | train_loss: 1.5097 | train_acc: 42.8964% | \n","\n","===== Checkpoint saved at epoch 50 =====\n","Epoch: 51 | train_loss: 1.5067 | train_acc: 43.3472% | \n","Epoch: 52 | train_loss: 1.5015 | train_acc: 43.4687% | \n","Epoch: 53 | train_loss: 1.4919 | train_acc: 43.7896% | \n","Epoch: 54 | train_loss: 1.4912 | train_acc: 43.7732% | \n","Epoch: 55 | train_loss: 1.4853 | train_acc: 44.2727% | \n","Epoch: 56 | train_loss: 1.4813 | train_acc: 44.3306% | \n","Epoch: 57 | train_loss: 1.4765 | train_acc: 44.7406% | \n","Epoch: 58 | train_loss: 1.4699 | train_acc: 44.9764% | \n","Epoch: 59 | train_loss: 1.4682 | train_acc: 44.9225% | \n","Epoch: 60 | train_loss: 1.4620 | train_acc: 45.2478% | \n","Epoch: 61 | train_loss: 1.4598 | train_acc: 45.3069% | \n","Epoch: 62 | train_loss: 1.4552 | train_acc: 45.6198% | \n","Epoch: 63 | train_loss: 1.4481 | train_acc: 45.8544% | \n","Epoch: 64 | train_loss: 1.4445 | train_acc: 45.9319% | \n","Epoch: 65 | train_loss: 1.4390 | train_acc: 46.7267% | \n","Epoch: 66 | train_loss: 1.4330 | train_acc: 46.5689% | \n","Epoch: 67 | train_loss: 1.4346 | train_acc: 46.4802% | \n","Epoch: 68 | train_loss: 1.4272 | train_acc: 46.7495% | \n","Epoch: 69 | train_loss: 1.4252 | train_acc: 46.7319% | \n","Epoch: 70 | train_loss: 1.4211 | train_acc: 47.1024% | \n","Epoch: 71 | train_loss: 1.4164 | train_acc: 47.3513% | \n","Epoch: 72 | train_loss: 1.4097 | train_acc: 47.7677% | \n","Epoch: 73 | train_loss: 1.4079 | train_acc: 47.5923% | \n","Epoch: 74 | train_loss: 1.3998 | train_acc: 47.8453% | \n","Epoch: 75 | train_loss: 1.4020 | train_acc: 47.9380% | \n","Epoch: 76 | train_loss: 1.3973 | train_acc: 48.2449% | \n","Epoch: 77 | train_loss: 1.3941 | train_acc: 48.5222% | \n","Epoch: 78 | train_loss: 1.3888 | train_acc: 48.5138% | \n","Epoch: 79 | train_loss: 1.3851 | train_acc: 48.6961% | \n","Epoch: 80 | train_loss: 1.3835 | train_acc: 48.8867% | \n","Epoch: 81 | train_loss: 1.3813 | train_acc: 49.0253% | \n","Epoch: 82 | train_loss: 1.3715 | train_acc: 49.3998% | \n","Epoch: 83 | train_loss: 1.3704 | train_acc: 49.3538% | \n","Epoch: 84 | train_loss: 1.3648 | train_acc: 49.5916% | \n","Epoch: 85 | train_loss: 1.3616 | train_acc: 49.7818% | \n","Epoch: 86 | train_loss: 1.3601 | train_acc: 50.0012% | \n","Epoch: 87 | train_loss: 1.3569 | train_acc: 49.9556% | \n","Epoch: 88 | train_loss: 1.3546 | train_acc: 50.1027% | \n","Epoch: 89 | train_loss: 1.3500 | train_acc: 50.2410% | \n","Epoch: 90 | train_loss: 1.3461 | train_acc: 50.4312% | \n","Epoch: 91 | train_loss: 1.3431 | train_acc: 50.5459% | \n","Epoch: 92 | train_loss: 1.3384 | train_acc: 50.9663% | \n","Epoch: 93 | train_loss: 1.3324 | train_acc: 50.9655% | \n","Epoch: 94 | train_loss: 1.3327 | train_acc: 51.1233% | \n","Epoch: 95 | train_loss: 1.3247 | train_acc: 51.3835% | \n","Epoch: 96 | train_loss: 1.3267 | train_acc: 51.3123% | \n","Epoch: 97 | train_loss: 1.3223 | train_acc: 51.5329% | \n","Epoch: 98 | train_loss: 1.3178 | train_acc: 51.5421% | \n","Epoch: 99 | train_loss: 1.3133 | train_acc: 51.8602% | \n","Epoch: 100 | train_loss: 1.3114 | train_acc: 51.9689% | \n","\n","===== Checkpoint saved at epoch 100 =====\n","Epoch: 101 | train_loss: 1.3108 | train_acc: 52.2155% | \n","Epoch: 102 | train_loss: 1.3071 | train_acc: 52.1995% | \n","Epoch: 103 | train_loss: 1.3020 | train_acc: 52.1919% | \n","Epoch: 104 | train_loss: 1.2931 | train_acc: 52.5060% | \n","Epoch: 105 | train_loss: 1.2920 | train_acc: 52.7582% | \n","Epoch: 106 | train_loss: 1.2935 | train_acc: 52.6894% | \n","Epoch: 107 | train_loss: 1.2872 | train_acc: 52.8117% | \n","Epoch: 108 | train_loss: 1.2858 | train_acc: 52.9436% | \n","Epoch: 109 | train_loss: 1.2811 | train_acc: 53.0027% | \n","Epoch: 110 | train_loss: 1.2835 | train_acc: 53.1230% | \n","Epoch: 111 | train_loss: 1.2763 | train_acc: 53.2329% | \n","Epoch: 112 | train_loss: 1.2713 | train_acc: 53.4795% | \n","Epoch: 113 | train_loss: 1.2685 | train_acc: 53.5878% | \n","Epoch: 114 | train_loss: 1.2662 | train_acc: 53.5410% | \n","Epoch: 115 | train_loss: 1.2605 | train_acc: 54.1376% | \n","Epoch: 116 | train_loss: 1.2597 | train_acc: 54.0353% | \n","Epoch: 117 | train_loss: 1.2567 | train_acc: 54.2935% | \n","Epoch: 118 | train_loss: 1.2520 | train_acc: 54.4473% | \n","Epoch: 119 | train_loss: 1.2518 | train_acc: 54.4134% | \n","Epoch: 120 | train_loss: 1.2459 | train_acc: 54.6411% | \n","Epoch: 121 | train_loss: 1.2437 | train_acc: 54.5061% | \n","Epoch: 122 | train_loss: 1.2392 | train_acc: 54.9700% | \n","Epoch: 123 | train_loss: 1.2387 | train_acc: 54.8981% | \n","Epoch: 124 | train_loss: 1.2316 | train_acc: 55.0627% | \n","Epoch: 125 | train_loss: 1.2369 | train_acc: 54.8394% | \n","Epoch: 126 | train_loss: 1.2271 | train_acc: 55.5443% | \n","Epoch: 127 | train_loss: 1.2262 | train_acc: 55.5075% | \n","Epoch: 128 | train_loss: 1.2218 | train_acc: 55.5790% | \n","Epoch: 129 | train_loss: 1.2171 | train_acc: 55.5651% | \n","Epoch: 130 | train_loss: 1.2120 | train_acc: 55.9487% | \n","Epoch: 131 | train_loss: 1.2146 | train_acc: 55.6726% | \n","Epoch: 132 | train_loss: 1.2109 | train_acc: 55.9587% | \n","Epoch: 133 | train_loss: 1.2070 | train_acc: 56.3827% | \n","Epoch: 134 | train_loss: 1.2047 | train_acc: 56.1809% | \n","Epoch: 135 | train_loss: 1.2012 | train_acc: 56.3103% | \n","Epoch: 136 | train_loss: 1.1956 | train_acc: 56.5637% | \n","Epoch: 137 | train_loss: 1.1939 | train_acc: 56.9361% | \n","Epoch: 138 | train_loss: 1.1937 | train_acc: 56.6744% | \n","Epoch: 139 | train_loss: 1.1874 | train_acc: 56.9645% | \n","Epoch: 140 | train_loss: 1.1891 | train_acc: 57.0976% | \n","Epoch: 141 | train_loss: 1.1801 | train_acc: 57.2446% | \n","Epoch: 142 | train_loss: 1.1825 | train_acc: 57.2099% | \n","Epoch: 143 | train_loss: 1.1746 | train_acc: 57.5180% | \n","Epoch: 144 | train_loss: 1.1738 | train_acc: 57.6179% | \n","Epoch: 145 | train_loss: 1.1734 | train_acc: 57.4021% | \n","Epoch: 146 | train_loss: 1.1685 | train_acc: 57.8385% | \n","Epoch: 147 | train_loss: 1.1665 | train_acc: 57.8856% | \n","Epoch: 148 | train_loss: 1.1642 | train_acc: 57.8441% | \n"]}]},{"cell_type":"markdown","source":["#### Resume training"],"metadata":{"id":"2pncz8J4Y7k4"}},{"cell_type":"code","source":["# Resume Training\n","MODEL_PATH = '/content/drive/MyDrive/NN_Course_Project/project/models'\n","checkpoint = torch.load(os.path.join(MODEL_PATH, 'resnet', 'resnet_cifar10_100.pt'))\n","Resnet_C10.load_state_dict(checkpoint['model'])\n","optimizer.load_state_dict(checkpoint['optimizer'])\n","scheduler.load_state_dict(checkpoint['scheduler'])"],"metadata":{"id":"djHk_5KhY-oS","executionInfo":{"status":"ok","timestamp":1681165196981,"user_tz":240,"elapsed":6253,"user":{"displayName":"Sharuka Promodya","userId":"04366359822682705905"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["start_time = timer()\n","VGG = TrainTestModel()\n","for state in optimizer.state.values():\n","  for k, v in state.items():\n","    if isinstance(v, torch.Tensor):\n","      state[k] = v.to(device)\n","      \n","ResNet.train(model=Resnet_C10, model_name='resnet', dataset='cifar10',\n","              train_dataloader=dataloader_train, optimizer=optimizer,\n","              scheduler=scheduler, epochs=300, device=device, \n","              resume_epoch=100) \n","\n","end_time = timer()\n","print(f\"Total training time: {end_time-start_time:.3f} seconds\")"],"metadata":{"id":"443qSxYLaLpE","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["dbd7225d3665454abef8f4b213b2352c","2f8d901df0514228a3dc7b9b18419fa1","daccf5f6a00248b4ab162a43bf80690d","23198c5f195a43dd97f2c61796d070fc","891aa2de400b411f8841c6cee9ebbf77","4c861137acf643e293d8f5136ddd7d31","8b830d7a63bf402aa9128cefc911b95f","59751320e92643918df6ad82903db137","84a9700af9b949a3a7393492a317959f","6b6093fe4c714c4bbcc4ac6c2607169d","a7baf7cb3640477cb68f404c98160910"]},"executionInfo":{"status":"error","timestamp":1681172112072,"user_tz":240,"elapsed":6911357,"user":{"displayName":"Sharuka Promodya","userId":"04366359822682705905"}},"outputId":"9c3c8e12-abba-4c25-8ce8-99aba6560795"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/200 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbd7225d3665454abef8f4b213b2352c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 101 | train_loss: 1.3091 | train_acc: 52.0045% | \n","Epoch: 102 | train_loss: 1.3065 | train_acc: 51.9685% | \n","Epoch: 103 | train_loss: 1.3012 | train_acc: 52.5292% | \n","Epoch: 104 | train_loss: 1.2963 | train_acc: 52.3481% | \n","Epoch: 105 | train_loss: 1.2944 | train_acc: 52.5859% | \n","Epoch: 106 | train_loss: 1.2885 | train_acc: 52.8041% | \n","Epoch: 107 | train_loss: 1.2860 | train_acc: 53.0611% | \n","Epoch: 108 | train_loss: 1.2874 | train_acc: 52.9839% | \n","Epoch: 109 | train_loss: 1.2825 | train_acc: 53.1773% | \n","Epoch: 110 | train_loss: 1.2801 | train_acc: 53.3040% | \n","Epoch: 111 | train_loss: 1.2776 | train_acc: 53.0655% | \n","Epoch: 112 | train_loss: 1.2710 | train_acc: 53.5945% | \n","Epoch: 113 | train_loss: 1.2667 | train_acc: 53.7780% | \n","Epoch: 114 | train_loss: 1.2685 | train_acc: 53.7124% | \n","Epoch: 115 | train_loss: 1.2621 | train_acc: 54.0125% | \n","Epoch: 116 | train_loss: 1.2562 | train_acc: 54.4961% | \n","Epoch: 117 | train_loss: 1.2550 | train_acc: 54.4170% | \n","Epoch: 118 | train_loss: 1.2552 | train_acc: 54.1824% | \n","Epoch: 119 | train_loss: 1.2491 | train_acc: 54.6787% | \n","Epoch: 120 | train_loss: 1.2485 | train_acc: 54.6084% | \n","Epoch: 121 | train_loss: 1.2430 | train_acc: 54.8457% | \n","Epoch: 122 | train_loss: 1.2406 | train_acc: 54.8829% | \n","Epoch: 123 | train_loss: 1.2365 | train_acc: 55.2482% | \n","Epoch: 124 | train_loss: 1.2372 | train_acc: 54.8174% | \n","Epoch: 125 | train_loss: 1.2285 | train_acc: 55.3645% | \n","Epoch: 126 | train_loss: 1.2278 | train_acc: 55.5758% | \n","Epoch: 127 | train_loss: 1.2234 | train_acc: 55.5794% | \n","Epoch: 128 | train_loss: 1.2208 | train_acc: 55.6873% | \n","Epoch: 129 | train_loss: 1.2159 | train_acc: 55.8324% | \n","Epoch: 130 | train_loss: 1.2119 | train_acc: 56.1385% | \n","Epoch: 131 | train_loss: 1.2108 | train_acc: 56.0882% | \n","Epoch: 132 | train_loss: 1.2073 | train_acc: 56.1121% | \n","Epoch: 133 | train_loss: 1.2056 | train_acc: 56.4866% | \n","Epoch: 134 | train_loss: 1.2025 | train_acc: 56.0386% | \n","Epoch: 135 | train_loss: 1.2059 | train_acc: 56.2764% | \n","Epoch: 136 | train_loss: 1.1965 | train_acc: 56.7623% | \n","Epoch: 137 | train_loss: 1.1923 | train_acc: 56.9785% | \n","Epoch: 138 | train_loss: 1.1910 | train_acc: 57.1491% | \n","Epoch: 139 | train_loss: 1.1910 | train_acc: 56.8626% | \n","Epoch: 140 | train_loss: 1.1886 | train_acc: 56.9657% | \n","Epoch: 141 | train_loss: 1.1770 | train_acc: 57.6259% | \n","Epoch: 142 | train_loss: 1.1808 | train_acc: 57.2035% | \n","Epoch: 143 | train_loss: 1.1764 | train_acc: 57.5144% | \n","Epoch: 144 | train_loss: 1.1749 | train_acc: 57.7558% | \n","Epoch: 145 | train_loss: 1.1733 | train_acc: 57.8117% | \n","Epoch: 146 | train_loss: 1.1665 | train_acc: 57.9108% | \n","Epoch: 147 | train_loss: 1.1653 | train_acc: 57.7282% | \n","Epoch: 148 | train_loss: 1.1588 | train_acc: 58.0742% | \n","Epoch: 149 | train_loss: 1.1628 | train_acc: 57.9424% | \n","Epoch: 150 | train_loss: 1.1555 | train_acc: 58.3608% | \n","\n","===== Checkpoint saved at epoch 150 =====\n","Epoch: 151 | train_loss: 1.1550 | train_acc: 58.3068% | \n","Epoch: 152 | train_loss: 1.1487 | train_acc: 58.4683% | \n","Epoch: 153 | train_loss: 1.1519 | train_acc: 58.4507% | \n","Epoch: 154 | train_loss: 1.1444 | train_acc: 58.9254% | \n","Epoch: 155 | train_loss: 1.1415 | train_acc: 58.8167% | \n","Epoch: 156 | train_loss: 1.1426 | train_acc: 58.7424% | \n","Epoch: 157 | train_loss: 1.1400 | train_acc: 58.6729% | \n","Epoch: 158 | train_loss: 1.1363 | train_acc: 59.0841% | \n","Epoch: 159 | train_loss: 1.1360 | train_acc: 59.1688% | \n","Epoch: 160 | train_loss: 1.1321 | train_acc: 59.4761% | \n","Epoch: 161 | train_loss: 1.1300 | train_acc: 59.3402% | \n","Epoch: 162 | train_loss: 1.1220 | train_acc: 59.6459% | \n","Epoch: 163 | train_loss: 1.1235 | train_acc: 59.3946% | \n","Epoch: 164 | train_loss: 1.1199 | train_acc: 59.7438% | \n","Epoch: 165 | train_loss: 1.1142 | train_acc: 59.8897% | \n","Epoch: 166 | train_loss: 1.1122 | train_acc: 60.0827% | \n","Epoch: 167 | train_loss: 1.1083 | train_acc: 60.2206% | \n","Epoch: 168 | train_loss: 1.1082 | train_acc: 60.2709% | \n","Epoch: 169 | train_loss: 1.1067 | train_acc: 60.6238% | \n","Epoch: 170 | train_loss: 1.1043 | train_acc: 60.3169% | \n","Epoch: 171 | train_loss: 1.1028 | train_acc: 60.4268% | \n","Epoch: 172 | train_loss: 1.0941 | train_acc: 60.8400% | \n","Epoch: 173 | train_loss: 1.0934 | train_acc: 60.7637% | \n","Epoch: 174 | train_loss: 1.0928 | train_acc: 60.8452% | \n","Epoch: 175 | train_loss: 1.0899 | train_acc: 61.0338% | \n","Epoch: 176 | train_loss: 1.0874 | train_acc: 60.9427% | \n","Epoch: 177 | train_loss: 1.0847 | train_acc: 61.1249% | \n","Epoch: 178 | train_loss: 1.0860 | train_acc: 61.1441% | \n","Epoch: 179 | train_loss: 1.0768 | train_acc: 61.2808% | \n","Epoch: 180 | train_loss: 1.0784 | train_acc: 61.4426% | \n","Epoch: 181 | train_loss: 1.0705 | train_acc: 61.7291% | \n","Epoch: 182 | train_loss: 1.0708 | train_acc: 61.6780% | \n","Epoch: 183 | train_loss: 1.0708 | train_acc: 61.8970% | \n","Epoch: 184 | train_loss: 1.0684 | train_acc: 61.8758% | \n","Epoch: 185 | train_loss: 1.0624 | train_acc: 61.9749% | \n","Epoch: 186 | train_loss: 1.0595 | train_acc: 62.1012% | \n","Epoch: 187 | train_loss: 1.0589 | train_acc: 62.0149% | \n","Epoch: 188 | train_loss: 1.0573 | train_acc: 62.1248% | \n","Epoch: 189 | train_loss: 1.0571 | train_acc: 61.9142% | \n","Epoch: 190 | train_loss: 1.0516 | train_acc: 62.3953% | \n","Epoch: 191 | train_loss: 1.0490 | train_acc: 62.6479% | \n","Epoch: 192 | train_loss: 1.0500 | train_acc: 62.4301% | \n","Epoch: 193 | train_loss: 1.0424 | train_acc: 62.9448% | \n","Epoch: 194 | train_loss: 1.0412 | train_acc: 62.9460% | \n","Epoch: 195 | train_loss: 1.0420 | train_acc: 62.9280% | \n","Epoch: 196 | train_loss: 1.0363 | train_acc: 62.9516% | \n","Epoch: 197 | train_loss: 1.0364 | train_acc: 62.9875% | \n","Epoch: 198 | train_loss: 1.0341 | train_acc: 63.2493% | \n","Epoch: 199 | train_loss: 1.0349 | train_acc: 63.0547% | \n","Epoch: 200 | train_loss: 1.0246 | train_acc: 63.5878% | \n","\n","===== Checkpoint saved at epoch 200 =====\n","Epoch: 201 | train_loss: 1.0281 | train_acc: 63.4467% | \n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-27d039149484>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m ResNet.train(model=Resnet_C10, model_name='resnet', dataset='cifar10',\n\u001b[0m\u001b[1;32m      9\u001b[0m               \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m               \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/NN_Course_Project/project/lib/train_test.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, model_name, dataset, train_dataloader, optimizer, scheduler, epochs, device, resume_epoch, checkpoint, is_CRL)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             train_loss, train_acc = self.train_step(model=model,\n\u001b[0m\u001b[1;32m    178\u001b[0m                                                     \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                                                     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/NN_Course_Project/project/lib/train_test.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, model, dataloader, optimizer, scheduler, device, epoch, is_CRL)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_CRL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/NN_Course_Project/project/lib/m_resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_block_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_block_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_block_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/NN_Course_Project/project/lib/m_resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["#### Testing"],"metadata":{"id":"e1ahBgtgiO_8"}},{"cell_type":"code","source":["# dataloaders for datasets\n","dataloader_train, dataloader_test = loader('CIFAR10')\n","Resnet_C10 = load_trained_model('resnet', 'cifar10', num_classes=10)\n","ResNet = TrainTestModel()"],"metadata":{"id":"ue5OqwdpiREn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_decos('eval')\n","\n","test_results = ResNet.test(model=Resnet_C10, dataloader=dataloader_test, \n","                        loss_fn=torch.nn.CrossEntropyLoss(), device=device)\n","\n","ResNet_C10_Metrics = MetricsComputation(test_results)\n","aurc, eaurc, fpr_in_tpr_95, pr_auc = ResNet_C10_Metrics.compute_metrics()\n","print_results(test_results[1], aurc, eaurc, pr_auc, fpr_in_tpr_95)"],"metadata":{"id":"f-Ap0BhbiqeM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CIFAR100 Dataset"],"metadata":{"id":"MVZxr6nCohpK"}},{"cell_type":"markdown","source":["#### VGG Model"],"metadata":{"id":"66KrkNs2YH1Z"}},{"cell_type":"markdown","source":["#### Training"],"metadata":{"id":"79FqkLGpi6Fr"}},{"cell_type":"code","source":["# dataloaders for datasets\n","dataloader_train, dataloader_test = loader('CIFAR100')\n","VGG_C100, optimizer, scheduler = load_model_opt_sch('vgg16', num_classes=100)"],"metadata":{"id":"ZuZ5DrUjYEnM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680579320265,"user_tz":240,"elapsed":3908,"user":{"displayName":"Sharuka Promodya","userId":"04366359822682705905"}},"outputId":"0c61b5a3-e9f0-4fba-d9f2-06fbd5f6a73e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Length of train dataloader: 391 batches of 128\n","Length of test dataloader: 79 batches of 128\n"]}]},{"cell_type":"code","source":["print_decos('train')\n","start_time = timer()\n","\n","VGG = TrainTestModel()\n","\n","# Training from the begining\n","VGG.train(model=VGG_C100, model_name='vgg16', dataset='cifar100',\n","          train_dataloader=dataloader_train, optimizer=optimizer,\n","          scheduler=scheduler, epochs=300, device=device) \n","\n","\n","end_time = timer()\n","print(f\"Total training time: {end_time-start_time:.3f} seconds\")"],"metadata":{"id":"e2sLQiUComt0","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c4d0a407d46c44738b294f5d6f8582ed","09873223f1414efcb6e462576a642775","fed8040e818b4d3bb5cb4f8c26e48964","d1d94a83d31643ab919e5b732a0bb288","1c6d4f0252c84203a45bf3878639c397","90dca1fd4b0946bda14d4bf3b4e624d2","cdf864da6cb5489fb77cb66cbb4d0516","80812a0a99f9471bb37a069abeccebc3","ad6609ff7fe84a62a2e274aac8fb8d44","912584fc22dc44b7a39e517c2b4e7125","7bbf6e7b686146bfbb1b2c6a24a2e13f"]},"outputId":"cabacb5d-c7c4-45fe-96a9-d1b5995659c1","executionInfo":{"status":"error","timestamp":1680578225237,"user_tz":240,"elapsed":92575,"user":{"displayName":"Sharuka Promodya","userId":"04366359822682705905"}}},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["========================================\n","TRAINING INITIATED\n","========================================\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4d0a407d46c44738b294f5d6f8582ed","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"output_type":"stream","name":"stdout","text":["Epoch: 1 | train_loss: 4.5160 | train_acc: 1.4690% | \n","Epoch: 2 | train_loss: 4.4779 | train_acc: 1.5429% | \n","Epoch: 3 | train_loss: 4.4734 | train_acc: 1.6728% | \n","Epoch: 4 | train_loss: 4.4726 | train_acc: 1.7012% | \n","Epoch: 5 | train_loss: 4.4697 | train_acc: 1.6204% | \n","Epoch: 6 | train_loss: 4.4677 | train_acc: 1.7223% | \n","Epoch: 7 | train_loss: 4.4654 | train_acc: 1.6496% | \n","Epoch: 8 | train_loss: 4.4631 | train_acc: 1.7088% | \n","Epoch: 9 | train_loss: 4.4614 | train_acc: 1.7016% | \n","Epoch: 10 | train_loss: 4.4614 | train_acc: 1.7799% | \n","Epoch: 11 | train_loss: 4.4588 | train_acc: 1.8666% | \n","Epoch: 12 | train_loss: 4.4575 | train_acc: 1.7675% | \n","Epoch: 13 | train_loss: 4.4542 | train_acc: 1.7835% | \n","Epoch: 14 | train_loss: 4.4530 | train_acc: 1.8822% | \n","Epoch: 15 | train_loss: 4.4514 | train_acc: 1.8942% | \n","Epoch: 16 | train_loss: 4.4497 | train_acc: 1.9321% | \n","Epoch: 17 | train_loss: 4.4469 | train_acc: 1.9913% | \n","Epoch: 18 | train_loss: 4.4467 | train_acc: 1.9625% | \n","Epoch: 19 | train_loss: 4.4456 | train_acc: 2.0328% | \n","Epoch: 20 | train_loss: 4.4436 | train_acc: 1.9653% | \n","Epoch: 21 | train_loss: 4.4418 | train_acc: 1.9218% | \n","Epoch: 22 | train_loss: 4.4408 | train_acc: 1.9174% | \n","Epoch: 23 | train_loss: 4.4389 | train_acc: 2.1224% | \n","Epoch: 24 | train_loss: 4.4368 | train_acc: 2.0456% | \n","Epoch: 25 | train_loss: 4.4362 | train_acc: 2.1216% | \n","Epoch: 26 | train_loss: 4.4349 | train_acc: 2.2163% | \n","Epoch: 27 | train_loss: 4.4330 | train_acc: 2.0049% | \n","Epoch: 28 | train_loss: 4.4316 | train_acc: 2.0780% | \n","Epoch: 29 | train_loss: 4.4293 | train_acc: 2.1891% | \n","Epoch: 30 | train_loss: 4.4286 | train_acc: 2.1995% | \n","Epoch: 31 | train_loss: 4.4280 | train_acc: 2.2550% | \n","Epoch: 32 | train_loss: 4.4252 | train_acc: 2.2151% | \n","Epoch: 33 | train_loss: 4.4247 | train_acc: 2.1292% | \n","Epoch: 34 | train_loss: 4.4228 | train_acc: 2.3501% | \n","Epoch: 35 | train_loss: 4.4208 | train_acc: 2.3370% | \n","Epoch: 36 | train_loss: 4.4203 | train_acc: 2.2383% | \n","Epoch: 37 | train_loss: 4.4167 | train_acc: 2.3026% | \n","Epoch: 38 | train_loss: 4.4158 | train_acc: 2.4061% | \n","Epoch: 39 | train_loss: 4.4145 | train_acc: 2.3202% | \n","Epoch: 40 | train_loss: 4.4120 | train_acc: 2.3441% | \n","Epoch: 41 | train_loss: 4.4104 | train_acc: 2.4852% | \n","Epoch: 42 | train_loss: 4.4092 | train_acc: 2.5735% | \n","Epoch: 43 | train_loss: 4.4064 | train_acc: 2.5348% | \n","Epoch: 44 | train_loss: 4.4059 | train_acc: 2.5400% | \n","Epoch: 45 | train_loss: 4.4034 | train_acc: 2.6091% | \n","Epoch: 46 | train_loss: 4.4014 | train_acc: 2.5000% | \n","Epoch: 47 | train_loss: 4.3991 | train_acc: 2.6251% | \n","Epoch: 48 | train_loss: 4.3968 | train_acc: 2.7362% | \n","Epoch: 49 | train_loss: 4.3946 | train_acc: 2.7506% | \n","Epoch: 50 | train_loss: 4.3942 | train_acc: 2.6395% | \n","\n","===== Checkpoint saved at epoch 50 =====\n","Epoch: 51 | train_loss: 4.3913 | train_acc: 2.7997% | \n","Epoch: 52 | train_loss: 4.3884 | train_acc: 2.7458% | \n","Epoch: 53 | train_loss: 4.3876 | train_acc: 2.8577% | \n","Epoch: 54 | train_loss: 4.3840 | train_acc: 2.7729% | \n","Epoch: 55 | train_loss: 4.3830 | train_acc: 2.7550% | \n","Epoch: 56 | train_loss: 4.3799 | train_acc: 2.8385% | \n","Epoch: 57 | train_loss: 4.3800 | train_acc: 2.7266% | \n","Epoch: 58 | train_loss: 4.3774 | train_acc: 2.8497% | \n","Epoch: 59 | train_loss: 4.3746 | train_acc: 2.9212% | \n","Epoch: 60 | train_loss: 4.3730 | train_acc: 2.9348% | \n","Epoch: 61 | train_loss: 4.3704 | train_acc: 2.9292% | \n","Epoch: 62 | train_loss: 4.3693 | train_acc: 2.8916% | \n","Epoch: 63 | train_loss: 4.3652 | train_acc: 2.9056% | \n","Epoch: 64 | train_loss: 4.3652 | train_acc: 3.0359% | \n","Epoch: 65 | train_loss: 4.3614 | train_acc: 2.9664% | \n","Epoch: 66 | train_loss: 4.3595 | train_acc: 3.1330% | \n","Epoch: 67 | train_loss: 4.3559 | train_acc: 3.0918% | \n","Epoch: 68 | train_loss: 4.3551 | train_acc: 3.1038% | \n","Epoch: 69 | train_loss: 4.3503 | train_acc: 3.2057% | \n","Epoch: 70 | train_loss: 4.3515 | train_acc: 3.1222% | \n","Epoch: 71 | train_loss: 4.3466 | train_acc: 3.0651% | \n","Epoch: 72 | train_loss: 4.3443 | train_acc: 3.1122% | \n","Epoch: 73 | train_loss: 4.3398 | train_acc: 3.1777% | \n","Epoch: 74 | train_loss: 4.3372 | train_acc: 3.2273% | \n","Epoch: 75 | train_loss: 4.3353 | train_acc: 3.1594% | \n","Epoch: 76 | train_loss: 4.3289 | train_acc: 3.2281% | \n","Epoch: 77 | train_loss: 4.3246 | train_acc: 3.2481% | \n","Epoch: 78 | train_loss: 4.3177 | train_acc: 3.2737% | \n","Epoch: 79 | train_loss: 4.3123 | train_acc: 3.3604% | \n","Epoch: 80 | train_loss: 4.3048 | train_acc: 3.3048% | \n","Epoch: 81 | train_loss: 4.2959 | train_acc: 3.3184% | \n","Epoch: 82 | train_loss: 4.2836 | train_acc: 3.4459% | \n","Epoch: 83 | train_loss: 4.2756 | train_acc: 3.4603% | \n","Epoch: 84 | train_loss: 4.2634 | train_acc: 3.5218% | \n","Epoch: 85 | train_loss: 4.2516 | train_acc: 3.6201% | \n","Epoch: 86 | train_loss: 4.2381 | train_acc: 3.6905% | \n","Epoch: 87 | train_loss: 4.2228 | train_acc: 3.7276% | \n","Epoch: 88 | train_loss: 4.2109 | train_acc: 3.7316% | \n","Epoch: 89 | train_loss: 4.1990 | train_acc: 3.7140% | \n","Epoch: 90 | train_loss: 4.1872 | train_acc: 3.7552% | \n","Epoch: 91 | train_loss: 4.1774 | train_acc: 3.9542% | \n","Epoch: 92 | train_loss: 4.1667 | train_acc: 3.9866% | \n","Epoch: 93 | train_loss: 4.1553 | train_acc: 4.0429% | \n","Epoch: 94 | train_loss: 4.1429 | train_acc: 3.9862% | \n","Epoch: 95 | train_loss: 4.1335 | train_acc: 4.0961% | \n","Epoch: 96 | train_loss: 4.1269 | train_acc: 4.1716% | \n","Epoch: 97 | train_loss: 4.1142 | train_acc: 4.3227% | \n","Epoch: 98 | train_loss: 4.1034 | train_acc: 4.3962% | \n","Epoch: 99 | train_loss: 4.0942 | train_acc: 4.4853% | \n","Epoch: 100 | train_loss: 4.0866 | train_acc: 4.4389% | \n","\n","===== Checkpoint saved at epoch 100 =====\n","Epoch: 101 | train_loss: 4.0782 | train_acc: 4.6671% | \n","Epoch: 102 | train_loss: 4.0676 | train_acc: 4.8062% | \n","Epoch: 103 | train_loss: 4.0629 | train_acc: 4.8541% | \n","Epoch: 104 | train_loss: 4.0524 | train_acc: 4.7970% | \n","Epoch: 105 | train_loss: 4.0461 | train_acc: 4.9341% | \n","Epoch: 106 | train_loss: 4.0358 | train_acc: 5.0815% | \n","Epoch: 107 | train_loss: 4.0264 | train_acc: 4.9261% | \n","Epoch: 108 | train_loss: 4.0196 | train_acc: 5.3449% | \n","Epoch: 109 | train_loss: 4.0124 | train_acc: 5.3996% | \n","Epoch: 110 | train_loss: 4.0039 | train_acc: 5.5291% | \n","Epoch: 111 | train_loss: 3.9975 | train_acc: 5.4244% | \n","Epoch: 112 | train_loss: 3.9861 | train_acc: 5.5926% | \n","Epoch: 113 | train_loss: 3.9795 | train_acc: 5.5567% | \n","Epoch: 114 | train_loss: 3.9696 | train_acc: 5.6849% | \n","Epoch: 115 | train_loss: 3.9610 | train_acc: 5.9223% | \n","Epoch: 116 | train_loss: 3.9521 | train_acc: 5.7617% | \n","Epoch: 117 | train_loss: 3.9440 | train_acc: 6.1069% | \n","Epoch: 118 | train_loss: 3.9321 | train_acc: 6.1397% | \n","Epoch: 119 | train_loss: 3.9231 | train_acc: 6.2688% | \n","Epoch: 120 | train_loss: 3.9116 | train_acc: 6.3691% | \n","Epoch: 121 | train_loss: 3.8997 | train_acc: 6.4754% | \n","Epoch: 122 | train_loss: 3.8905 | train_acc: 6.7459% | \n","Epoch: 123 | train_loss: 3.8818 | train_acc: 6.6548% | \n","Epoch: 124 | train_loss: 3.8709 | train_acc: 6.7635% | \n","Epoch: 125 | train_loss: 3.8610 | train_acc: 6.8778% | \n","Epoch: 126 | train_loss: 3.8527 | train_acc: 7.0724% | \n","Epoch: 127 | train_loss: 3.8405 | train_acc: 7.0884% | \n","Epoch: 128 | train_loss: 3.8328 | train_acc: 7.1539% | \n","Epoch: 129 | train_loss: 3.8247 | train_acc: 7.2027% | \n","Epoch: 130 | train_loss: 3.8108 | train_acc: 7.0904% | \n","Epoch: 131 | train_loss: 3.8059 | train_acc: 7.3957% | \n","Epoch: 132 | train_loss: 3.8013 | train_acc: 7.3841% | \n","Epoch: 133 | train_loss: 3.7908 | train_acc: 7.5460% | \n","Epoch: 134 | train_loss: 3.7807 | train_acc: 7.6626% | \n","Epoch: 135 | train_loss: 3.7711 | train_acc: 7.9244% | \n","Epoch: 136 | train_loss: 3.7669 | train_acc: 7.9632% | \n","Epoch: 137 | train_loss: 3.7619 | train_acc: 7.7294% | \n","Epoch: 138 | train_loss: 3.7527 | train_acc: 7.8485% | \n","Epoch: 139 | train_loss: 3.7447 | train_acc: 8.0227% | \n","Epoch: 140 | train_loss: 3.7348 | train_acc: 8.1510% | \n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-50cac75828c9>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Training from the begining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m VGG.train(model=VGG_C100, model_name='vgg16', dataset='cifar100',\n\u001b[0m\u001b[1;32m      8\u001b[0m           \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           scheduler=scheduler, epochs=300, device=device) \n","\u001b[0;32m/content/drive/MyDrive/NN_Course_Project/project/lib/train_test.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, model_name, dataset, train_dataloader, optimizer, scheduler, epochs, device, resume_epoch, checkpoint, is_CRL)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 train_loss, train_acc = self.train_step(model=model,\n\u001b[0m\u001b[1;32m    207\u001b[0m                                                         \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                                                         \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/NN_Course_Project/project/lib/train_test.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, model, dataloader, optimizer, scheduler, device, epoch, is_CRL)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_CRL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/NN_Course_Project/project/lib/m_vgg16.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["#### Resume Training"],"metadata":{"id":"8y4yL5iLi8yF"}},{"cell_type":"code","source":["# Resume Training\n","MODEL_PATH = '/content/drive/MyDrive/NN_Course_Project/project/models'\n","checkpoint = torch.load(os.path.join(MODEL_PATH, 'vgg16', 'vgg16_cifar100_100.pt'))\n","VGG_C100.load_state_dict(checkpoint['model'])\n","optimizer.load_state_dict(checkpoint['optimizer'])\n","scheduler.load_state_dict(checkpoint['scheduler'])"],"metadata":{"id":"N9S1yhrTRo4-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start_time = timer()\n","VGG = TrainTestModel()\n","for state in optimizer.state.values():\n","  for k, v in state.items():\n","    if isinstance(v, torch.Tensor):\n","      state[k] = v.to(device)\n","      \n","VGG.train(model=VGG_C100, model_name='vgg16', dataset='cifar100',\n","              train_dataloader=dataloader_train, optimizer=optimizer,\n","              scheduler=scheduler, epochs=300, device=device, \n","              resume_epoch=100) \n","\n","end_time = timer()\n","print(f\"Total training time: {end_time-start_time:.3f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d7d039f0d5504f409409e07f30263926","86bfe0b6bd50400b9a46e61c91e55fa4","b59d6329557c41b4a99593a59a258bb3","623a16e962a54cf4b6c97b58ff951d79","c516bde9d799497bb458687bf22f4366","5e50865748eb4cd89bc9ed99e1aaf4ca","7f69fb68b0834692ba679137bd25f20a","c45e8b27a9314bca8b34837795d181dd","1d10905baa8e43dda2e50efd45b4bd9e","f28fa7e211b44318a5331fde4ce68954","c16c24ba67194d0798739e6fb1cb1272"]},"id":"ej9FVlKbSMkm","executionInfo":{"status":"ok","timestamp":1680585198248,"user_tz":240,"elapsed":5368260,"user":{"displayName":"Sharuka Promodya","userId":"04366359822682705905"}},"outputId":"33e32fc5-c127-4bf4-8d18-9dcbad601208"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/200 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7d039f0d5504f409409e07f30263926"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 101 | train_loss: 4.0769 | train_acc: 4.5400% | \n","Epoch: 102 | train_loss: 4.0703 | train_acc: 4.6619% | \n","Epoch: 103 | train_loss: 4.0595 | train_acc: 4.6847% | \n","Epoch: 104 | train_loss: 4.0533 | train_acc: 4.8789% | \n","Epoch: 105 | train_loss: 4.0476 | train_acc: 5.0044% | \n","Epoch: 106 | train_loss: 4.0356 | train_acc: 5.1235% | \n","Epoch: 107 | train_loss: 4.0271 | train_acc: 5.1942% | \n","Epoch: 108 | train_loss: 4.0248 | train_acc: 5.1838% | \n","Epoch: 109 | train_loss: 4.0131 | train_acc: 5.2382% | \n","Epoch: 110 | train_loss: 4.0061 | train_acc: 5.3876% | \n","Epoch: 111 | train_loss: 3.9967 | train_acc: 5.2693% | \n","Epoch: 112 | train_loss: 3.9875 | train_acc: 5.7097% | \n","Epoch: 113 | train_loss: 3.9756 | train_acc: 5.7289% | \n","Epoch: 114 | train_loss: 3.9694 | train_acc: 5.7781% | \n","Epoch: 115 | train_loss: 3.9644 | train_acc: 5.7880% | \n","Epoch: 116 | train_loss: 3.9519 | train_acc: 5.9439% | \n","Epoch: 117 | train_loss: 3.9435 | train_acc: 6.0446% | \n","Epoch: 118 | train_loss: 3.9353 | train_acc: 6.3587% | \n","Epoch: 119 | train_loss: 3.9219 | train_acc: 6.3235% | \n","Epoch: 120 | train_loss: 3.9123 | train_acc: 6.3195% | \n","Epoch: 121 | train_loss: 3.8991 | train_acc: 6.5058% | \n","Epoch: 122 | train_loss: 3.8910 | train_acc: 6.6316% | \n","Epoch: 123 | train_loss: 3.8783 | train_acc: 6.7507% | \n","Epoch: 124 | train_loss: 3.8703 | train_acc: 6.5485% | \n","Epoch: 125 | train_loss: 3.8634 | train_acc: 6.9086% | \n","Epoch: 126 | train_loss: 3.8516 | train_acc: 7.0352% | \n","Epoch: 127 | train_loss: 3.8417 | train_acc: 7.0217% | \n","Epoch: 128 | train_loss: 3.8274 | train_acc: 7.1312% | \n","Epoch: 129 | train_loss: 3.8265 | train_acc: 7.3274% | \n","Epoch: 130 | train_loss: 3.8174 | train_acc: 7.4173% | \n","Epoch: 131 | train_loss: 3.8081 | train_acc: 7.4293% | \n","Epoch: 132 | train_loss: 3.7974 | train_acc: 7.2842% | \n","Epoch: 133 | train_loss: 3.7918 | train_acc: 7.5512% | \n","Epoch: 134 | train_loss: 3.7861 | train_acc: 7.7226% | \n","Epoch: 135 | train_loss: 3.7735 | train_acc: 7.7741% | \n","Epoch: 136 | train_loss: 3.7663 | train_acc: 7.9508% | \n","Epoch: 137 | train_loss: 3.7632 | train_acc: 7.7909% | \n","Epoch: 138 | train_loss: 3.7539 | train_acc: 8.0659% | \n","Epoch: 139 | train_loss: 3.7496 | train_acc: 8.0567% | \n","Epoch: 140 | train_loss: 3.7358 | train_acc: 8.1546% | \n","Epoch: 141 | train_loss: 3.7280 | train_acc: 8.2761% | \n","Epoch: 142 | train_loss: 3.7232 | train_acc: 8.2073% | \n","Epoch: 143 | train_loss: 3.7135 | train_acc: 8.3296% | \n","Epoch: 144 | train_loss: 3.7090 | train_acc: 8.4051% | \n","Epoch: 145 | train_loss: 3.7009 | train_acc: 8.4119% | \n","Epoch: 146 | train_loss: 3.6900 | train_acc: 8.6685% | \n","Epoch: 147 | train_loss: 3.6880 | train_acc: 8.7872% | \n","Epoch: 148 | train_loss: 3.6838 | train_acc: 8.5698% | \n","Epoch: 149 | train_loss: 3.6654 | train_acc: 8.7956% | \n","Epoch: 150 | train_loss: 3.6617 | train_acc: 9.0509% | \n","\n","===== Checkpoint saved at epoch 150 =====\n","Epoch: 151 | train_loss: 3.6561 | train_acc: 9.0593% | \n","Epoch: 152 | train_loss: 3.6502 | train_acc: 9.3598% | \n","Epoch: 153 | train_loss: 3.6443 | train_acc: 9.1772% | \n","Epoch: 154 | train_loss: 3.6410 | train_acc: 9.3850% | \n","Epoch: 155 | train_loss: 3.6307 | train_acc: 9.4477% | \n","Epoch: 156 | train_loss: 3.6210 | train_acc: 9.5852% | \n","Epoch: 157 | train_loss: 3.6154 | train_acc: 9.8098% | \n","Epoch: 158 | train_loss: 3.6098 | train_acc: 9.6000% | \n","Epoch: 159 | train_loss: 3.6029 | train_acc: 9.9816% | \n","Epoch: 160 | train_loss: 3.5959 | train_acc: 10.0332% | \n","Epoch: 161 | train_loss: 3.5885 | train_acc: 10.2258% | \n","Epoch: 162 | train_loss: 3.5770 | train_acc: 10.2713% | \n","Epoch: 163 | train_loss: 3.5750 | train_acc: 10.3185% | \n","Epoch: 164 | train_loss: 3.5684 | train_acc: 10.4352% | \n","Epoch: 165 | train_loss: 3.5643 | train_acc: 10.3229% | \n","Epoch: 166 | train_loss: 3.5591 | train_acc: 10.3025% | \n","Epoch: 167 | train_loss: 3.5528 | train_acc: 10.4971% | \n","Epoch: 168 | train_loss: 3.5399 | train_acc: 10.8040% | \n","Epoch: 169 | train_loss: 3.5328 | train_acc: 10.9986% | \n","Epoch: 170 | train_loss: 3.5281 | train_acc: 11.0250% | \n","Epoch: 171 | train_loss: 3.5213 | train_acc: 10.9954% | \n","Epoch: 172 | train_loss: 3.5109 | train_acc: 11.1984% | \n","Epoch: 173 | train_loss: 3.5029 | train_acc: 11.2696% | \n","Epoch: 174 | train_loss: 3.4982 | train_acc: 11.3139% | \n","Epoch: 175 | train_loss: 3.4871 | train_acc: 11.7076% | \n","Epoch: 176 | train_loss: 3.4817 | train_acc: 11.6292% | \n","Epoch: 177 | train_loss: 3.4775 | train_acc: 11.7203% | \n","Epoch: 178 | train_loss: 3.4633 | train_acc: 11.8310% | \n","Epoch: 179 | train_loss: 3.4628 | train_acc: 12.0364% | \n","Epoch: 180 | train_loss: 3.4506 | train_acc: 11.9681% | \n","Epoch: 181 | train_loss: 3.4453 | train_acc: 12.0472% | \n","Epoch: 182 | train_loss: 3.4348 | train_acc: 12.4496% | \n","Epoch: 183 | train_loss: 3.4274 | train_acc: 12.5396% | \n","Epoch: 184 | train_loss: 3.4216 | train_acc: 12.6818% | \n","Epoch: 185 | train_loss: 3.4182 | train_acc: 12.4197% | \n","Epoch: 186 | train_loss: 3.4124 | train_acc: 12.7242% | \n","Epoch: 187 | train_loss: 3.4048 | train_acc: 12.7230% | \n","Epoch: 188 | train_loss: 3.3952 | train_acc: 12.9376% | \n","Epoch: 189 | train_loss: 3.3908 | train_acc: 13.1758% | \n","Epoch: 190 | train_loss: 3.3756 | train_acc: 13.1917% | \n","Epoch: 191 | train_loss: 3.3767 | train_acc: 13.1985% | \n","Epoch: 192 | train_loss: 3.3616 | train_acc: 13.5166% | \n","Epoch: 193 | train_loss: 3.3579 | train_acc: 13.5378% | \n","Epoch: 194 | train_loss: 3.3501 | train_acc: 13.5674% | \n","Epoch: 195 | train_loss: 3.3416 | train_acc: 13.6297% | \n","Epoch: 196 | train_loss: 3.3382 | train_acc: 13.8443% | \n","Epoch: 197 | train_loss: 3.3265 | train_acc: 13.9694% | \n","Epoch: 198 | train_loss: 3.3191 | train_acc: 14.1492% | \n","Epoch: 199 | train_loss: 3.3169 | train_acc: 14.1013% | \n","Epoch: 200 | train_loss: 3.3080 | train_acc: 14.4401% | \n","\n","===== Checkpoint saved at epoch 200 =====\n","Epoch: 201 | train_loss: 3.2951 | train_acc: 14.6555% | \n","Epoch: 202 | train_loss: 3.2923 | train_acc: 14.7418% | \n","Epoch: 203 | train_loss: 3.2811 | train_acc: 14.7882% | \n","Epoch: 204 | train_loss: 3.2776 | train_acc: 14.8597% | \n","Epoch: 205 | train_loss: 3.2729 | train_acc: 14.8957% | \n","Epoch: 206 | train_loss: 3.2652 | train_acc: 15.1882% | \n","Epoch: 207 | train_loss: 3.2543 | train_acc: 15.1255% | \n","Epoch: 208 | train_loss: 3.2506 | train_acc: 15.3229% | \n","Epoch: 209 | train_loss: 3.2413 | train_acc: 15.3441% | \n","Epoch: 210 | train_loss: 3.2358 | train_acc: 15.4767% | \n","Epoch: 211 | train_loss: 3.2270 | train_acc: 15.6030% | \n","Epoch: 212 | train_loss: 3.2244 | train_acc: 15.3824% | \n","Epoch: 213 | train_loss: 3.2136 | train_acc: 15.7872% | \n","Epoch: 214 | train_loss: 3.2048 | train_acc: 16.2216% | \n","Epoch: 215 | train_loss: 3.2014 | train_acc: 15.9775% | \n","Epoch: 216 | train_loss: 3.1914 | train_acc: 16.4258% | \n","Epoch: 217 | train_loss: 3.1830 | train_acc: 16.3815% | \n","Epoch: 218 | train_loss: 3.1820 | train_acc: 16.3639% | \n","Epoch: 219 | train_loss: 3.1712 | train_acc: 16.6536% | \n","Epoch: 220 | train_loss: 3.1642 | train_acc: 16.6592% | \n","Epoch: 221 | train_loss: 3.1634 | train_acc: 16.7707% | \n","Epoch: 222 | train_loss: 3.1527 | train_acc: 16.8195% | \n","Epoch: 223 | train_loss: 3.1416 | train_acc: 16.9242% | \n","Epoch: 224 | train_loss: 3.1423 | train_acc: 17.0153% | \n","Epoch: 225 | train_loss: 3.1351 | train_acc: 17.1983% | \n","Epoch: 226 | train_loss: 3.1266 | train_acc: 17.3038% | \n","Epoch: 227 | train_loss: 3.1179 | train_acc: 17.7973% | \n","Epoch: 228 | train_loss: 3.1087 | train_acc: 17.7102% | \n","Epoch: 229 | train_loss: 3.1043 | train_acc: 17.6578% | \n","Epoch: 230 | train_loss: 3.1014 | train_acc: 17.6842% | \n","Epoch: 231 | train_loss: 3.0947 | train_acc: 17.8545% | \n","Epoch: 232 | train_loss: 3.0854 | train_acc: 17.9688% | \n","Epoch: 233 | train_loss: 3.0789 | train_acc: 18.0411% | \n","Epoch: 234 | train_loss: 3.0689 | train_acc: 18.4043% | \n","Epoch: 235 | train_loss: 3.0693 | train_acc: 18.4447% | \n","Epoch: 236 | train_loss: 3.0653 | train_acc: 18.4978% | \n","Epoch: 237 | train_loss: 3.0512 | train_acc: 18.6577% | \n","Epoch: 238 | train_loss: 3.0440 | train_acc: 18.7280% | \n","Epoch: 239 | train_loss: 3.0429 | train_acc: 18.7212% | \n","Epoch: 240 | train_loss: 3.0301 | train_acc: 18.8675% | \n","Epoch: 241 | train_loss: 3.0241 | train_acc: 19.2104% | \n","Epoch: 242 | train_loss: 3.0231 | train_acc: 19.2579% | \n","Epoch: 243 | train_loss: 3.0114 | train_acc: 19.2487% | \n","Epoch: 244 | train_loss: 3.0077 | train_acc: 19.5496% | \n","Epoch: 245 | train_loss: 3.0057 | train_acc: 19.3970% | \n","Epoch: 246 | train_loss: 3.0007 | train_acc: 19.3710% | \n","Epoch: 247 | train_loss: 2.9909 | train_acc: 20.0392% | \n","Epoch: 248 | train_loss: 2.9857 | train_acc: 19.6232% | \n","Epoch: 249 | train_loss: 2.9779 | train_acc: 20.0759% | \n","Epoch: 250 | train_loss: 2.9691 | train_acc: 20.1175% | \n","\n","===== Checkpoint saved at epoch 250 =====\n","Epoch: 251 | train_loss: 2.9630 | train_acc: 20.2458% | \n","Epoch: 252 | train_loss: 2.9561 | train_acc: 20.3784% | \n","Epoch: 253 | train_loss: 2.9558 | train_acc: 20.4248% | \n","Epoch: 254 | train_loss: 2.9428 | train_acc: 20.7848% | \n","Epoch: 255 | train_loss: 2.9431 | train_acc: 20.6114% | \n","Epoch: 256 | train_loss: 2.9344 | train_acc: 20.8987% | \n","Epoch: 257 | train_loss: 2.9255 | train_acc: 21.1569% | \n","Epoch: 258 | train_loss: 2.9163 | train_acc: 21.1129% | \n","Epoch: 259 | train_loss: 2.9211 | train_acc: 21.1117% | \n","Epoch: 260 | train_loss: 2.9026 | train_acc: 21.4886% | \n","Epoch: 261 | train_loss: 2.9026 | train_acc: 21.2292% | \n","Epoch: 262 | train_loss: 2.8941 | train_acc: 21.6013% | \n","Epoch: 263 | train_loss: 2.8905 | train_acc: 21.6672% | \n","Epoch: 264 | train_loss: 2.8822 | train_acc: 21.9305% | \n","Epoch: 265 | train_loss: 2.8754 | train_acc: 21.8854% | \n","Epoch: 266 | train_loss: 2.8664 | train_acc: 22.1371% | \n","Epoch: 267 | train_loss: 2.8651 | train_acc: 22.1399% | \n","Epoch: 268 | train_loss: 2.8539 | train_acc: 22.3170% | \n","Epoch: 269 | train_loss: 2.8557 | train_acc: 22.2079% | \n","Epoch: 270 | train_loss: 2.8425 | train_acc: 22.4720% | \n","Epoch: 271 | train_loss: 2.8417 | train_acc: 22.5208% | \n","Epoch: 272 | train_loss: 2.8362 | train_acc: 22.8181% | \n","Epoch: 273 | train_loss: 2.8310 | train_acc: 23.0806% | \n","Epoch: 274 | train_loss: 2.8225 | train_acc: 22.7625% | \n","Epoch: 275 | train_loss: 2.8169 | train_acc: 23.0595% | \n","Epoch: 276 | train_loss: 2.8098 | train_acc: 23.3492% | \n","Epoch: 277 | train_loss: 2.8113 | train_acc: 23.3652% | \n","Epoch: 278 | train_loss: 2.8003 | train_acc: 23.2633% | \n","Epoch: 279 | train_loss: 2.7941 | train_acc: 23.5118% | \n","Epoch: 280 | train_loss: 2.7897 | train_acc: 23.3816% | \n","Epoch: 281 | train_loss: 2.7820 | train_acc: 23.6033% | \n","Epoch: 282 | train_loss: 2.7667 | train_acc: 23.8307% | \n","Epoch: 283 | train_loss: 2.7654 | train_acc: 24.1252% | \n","Epoch: 284 | train_loss: 2.7636 | train_acc: 23.9778% | \n","Epoch: 285 | train_loss: 2.7579 | train_acc: 24.1876% | \n","Epoch: 286 | train_loss: 2.7473 | train_acc: 24.5484% | \n","Epoch: 287 | train_loss: 2.7419 | train_acc: 24.5684% | \n","Epoch: 288 | train_loss: 2.7400 | train_acc: 24.5504% | \n","Epoch: 289 | train_loss: 2.7313 | train_acc: 24.3962% | \n","Epoch: 290 | train_loss: 2.7305 | train_acc: 24.8681% | \n","Epoch: 291 | train_loss: 2.7228 | train_acc: 24.9560% | \n","Epoch: 292 | train_loss: 2.7119 | train_acc: 24.9744% | \n","Epoch: 293 | train_loss: 2.7094 | train_acc: 25.1499% | \n","Epoch: 294 | train_loss: 2.6955 | train_acc: 25.2278% | \n","Epoch: 295 | train_loss: 2.7041 | train_acc: 25.1415% | \n","Epoch: 296 | train_loss: 2.6881 | train_acc: 25.4791% | \n","Epoch: 297 | train_loss: 2.6853 | train_acc: 25.7373% | \n","Epoch: 298 | train_loss: 2.6727 | train_acc: 25.7481% | \n","Epoch: 299 | train_loss: 2.6748 | train_acc: 25.7445% | \n","Epoch: 300 | train_loss: 2.6647 | train_acc: 25.8264% | \n","\n","===== Checkpoint saved at epoch 300 =====\n","Total training time: 5368.034 seconds\n"]}]},{"cell_type":"markdown","source":["#### Testing"],"metadata":{"id":"dxU_izdCM1jY"}},{"cell_type":"code","source":["# dataloaders for datasets\n","dataloader_train, dataloader_test = loader('CIFAR100')\n","VGG_C100 = load_trained_model('vgg16', 'cifar100', num_classes=100)\n","VGG = TrainTestModel()"],"metadata":{"id":"aEdCn9_9jHgw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_decos('eval')\n","\n","test_results = VGG.test(model=VGG_C100, dataloader=dataloader_test, \n","                        loss_fn=torch.nn.CrossEntropyLoss(), device=device)\n","\n","VGG_C100_Metrics = MetricsComputation(test_results)\n","aurc, eaurc, fpr_in_tpr_95, pr_auc = VGG_C100_Metrics.compute_metrics()\n","print_results(test_results[1], aurc, eaurc, pr_auc, fpr_in_tpr_95)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C6RwXvXyMgdX","executionInfo":{"status":"ok","timestamp":1680585254373,"user_tz":240,"elapsed":3063,"user":{"displayName":"Sharuka Promodya","userId":"04366359822682705905"}},"outputId":"322681b0-bd9c-4d25-8125-67f5f7e85e4d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","========================================\n","EVALUATION RESULTS\n","========================================\n","\n","Test Accuracy: 27.946993670886076\n","Area Under Risk Curve (AURC): 0.9375\n","Excessive-AURC (E-AURC): 0.4388705812946884\n","Area Under Precision-Recall Curve (AUPR): 0.653265747504568\n","False Positive Rate (FPR) at 95% True Positive Rate (TPR): 0.744266851980542\n","\n"]}]},{"cell_type":"markdown","source":["### ResNet Model"],"metadata":{"id":"7H59dYDzjYfc"}},{"cell_type":"markdown","source":["#### Training"],"metadata":{"id":"6Cs51FWoja03"}},{"cell_type":"code","source":["# dataloaders for datasets\n","dataloader_train, dataloader_test = loader('CIFAR100')\n","Resnet_C100, optimizer, scheduler = load_model_opt_sch('resnet', num_classes=100)\n","ResNet = TrainTestModel()"],"metadata":{"id":"xHxPL2t0jc-x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Mb2jkibGjiko"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_decos('train')\n","start_time = timer()\n","\n","# Training from the begining\n","ResNet.train(model=Resnet_C100, model_name='resnet', dataset='cifar100', \n","          train_dataloader=dataloader_train, optimizer=optimizer,\n","          scheduler=scheduler, epochs=300, device=device) \n","\n","end_time = timer()\n","print(f\"Total training time: {end_time-start_time:.3f} seconds\")"],"metadata":{"id":"yH4eRZUsjkvR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Testing"],"metadata":{"id":"lwT3fBTYjoPS"}},{"cell_type":"code","source":["# dataloaders for datasets\n","dataloader_train, dataloader_test = loader('CIFAR100')\n","Resnet_C100 = load_trained_model('resnet', 'cifar100', num_classes=10)\n","ResNet = TrainTestModel()"],"metadata":{"id":"qrcqCaKfjqgx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_decos('eval')\n","\n","test_results = ResNet.test(model=Resnet_C100, dataloader=dataloader_test, \n","                        loss_fn=torch.nn.CrossEntropyLoss(), device=device)\n","\n","ResNet_C100_Metrics = MetricsComputation(test_results)\n","aurc, eaurc, fpr_in_tpr_95, pr_auc = ResNet_C100_Metrics.compute_metrics()\n","print_results(test_results[1], aurc, eaurc, pr_auc, fpr_in_tpr_95)"],"metadata":{"id":"d8DkXAamj7hy"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"orig_nbformat":4,"colab":{"provenance":[]},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"fbe14ee5fd104e73b2cfec9ce3d4b6b0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d52ed8b855c348ba918168949673ae8a","IPY_MODEL_604ac3f2d24946bf9ccd82d42ae4a880","IPY_MODEL_62ab785b88a54be5a33e112d0e50a66e"],"layout":"IPY_MODEL_e34d2d3845c04618a53bf386d5ab320d"}},"d52ed8b855c348ba918168949673ae8a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af69d184f48c45b5ae0ceea58c2a9961","placeholder":"","style":"IPY_MODEL_a5dc66de2843448282ecb8d6114a1da7","value":"100%"}},"604ac3f2d24946bf9ccd82d42ae4a880":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e3a5365f2034d7bbc183cf8d6608f05","max":300,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2aba127deac94805b044991b2757ecc8","value":300}},"62ab785b88a54be5a33e112d0e50a66e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7175af3b6c8b408582531aafafe752fb","placeholder":"","style":"IPY_MODEL_99c87cc35008418590a46d0a8566a48e","value":" 300/300 [2:20:26&lt;00:00, 28.07s/it]"}},"e34d2d3845c04618a53bf386d5ab320d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af69d184f48c45b5ae0ceea58c2a9961":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5dc66de2843448282ecb8d6114a1da7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e3a5365f2034d7bbc183cf8d6608f05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2aba127deac94805b044991b2757ecc8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7175af3b6c8b408582531aafafe752fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99c87cc35008418590a46d0a8566a48e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4d0a407d46c44738b294f5d6f8582ed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_09873223f1414efcb6e462576a642775","IPY_MODEL_fed8040e818b4d3bb5cb4f8c26e48964","IPY_MODEL_d1d94a83d31643ab919e5b732a0bb288"],"layout":"IPY_MODEL_1c6d4f0252c84203a45bf3878639c397"}},"09873223f1414efcb6e462576a642775":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90dca1fd4b0946bda14d4bf3b4e624d2","placeholder":"","style":"IPY_MODEL_cdf864da6cb5489fb77cb66cbb4d0516","value":" 47%"}},"fed8040e818b4d3bb5cb4f8c26e48964":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_80812a0a99f9471bb37a069abeccebc3","max":300,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad6609ff7fe84a62a2e274aac8fb8d44","value":140}},"d1d94a83d31643ab919e5b732a0bb288":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_912584fc22dc44b7a39e517c2b4e7125","placeholder":"","style":"IPY_MODEL_7bbf6e7b686146bfbb1b2c6a24a2e13f","value":" 140/300 [1:05:25&lt;1:13:00, 27.38s/it]"}},"1c6d4f0252c84203a45bf3878639c397":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90dca1fd4b0946bda14d4bf3b4e624d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdf864da6cb5489fb77cb66cbb4d0516":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80812a0a99f9471bb37a069abeccebc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad6609ff7fe84a62a2e274aac8fb8d44":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"912584fc22dc44b7a39e517c2b4e7125":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bbf6e7b686146bfbb1b2c6a24a2e13f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7d039f0d5504f409409e07f30263926":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_86bfe0b6bd50400b9a46e61c91e55fa4","IPY_MODEL_b59d6329557c41b4a99593a59a258bb3","IPY_MODEL_623a16e962a54cf4b6c97b58ff951d79"],"layout":"IPY_MODEL_c516bde9d799497bb458687bf22f4366"}},"86bfe0b6bd50400b9a46e61c91e55fa4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e50865748eb4cd89bc9ed99e1aaf4ca","placeholder":"","style":"IPY_MODEL_7f69fb68b0834692ba679137bd25f20a","value":"100%"}},"b59d6329557c41b4a99593a59a258bb3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c45e8b27a9314bca8b34837795d181dd","max":200,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1d10905baa8e43dda2e50efd45b4bd9e","value":200}},"623a16e962a54cf4b6c97b58ff951d79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f28fa7e211b44318a5331fde4ce68954","placeholder":"","style":"IPY_MODEL_c16c24ba67194d0798739e6fb1cb1272","value":" 200/200 [1:29:28&lt;00:00, 27.02s/it]"}},"c516bde9d799497bb458687bf22f4366":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e50865748eb4cd89bc9ed99e1aaf4ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f69fb68b0834692ba679137bd25f20a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c45e8b27a9314bca8b34837795d181dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d10905baa8e43dda2e50efd45b4bd9e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f28fa7e211b44318a5331fde4ce68954":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c16c24ba67194d0798739e6fb1cb1272":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e94aad9f0f5d46a6949345acd3d82f76":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_783266d22d53406f99e5ed34ba466803","IPY_MODEL_72cd8935f5aa453780424235c37e6c47","IPY_MODEL_10f157a48fbb42a3a2ac674dee40861d"],"layout":"IPY_MODEL_4c823dbdde1c461d9489c2b04956c2f2"}},"783266d22d53406f99e5ed34ba466803":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac7cd2ac36c048d5b38dd1a4fe66aa3d","placeholder":"","style":"IPY_MODEL_060caeb4ac0f4008907170511c40bc33","value":" 49%"}},"72cd8935f5aa453780424235c37e6c47":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcb6e5a626e8419cb4002e1007b02454","max":300,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8943160977e443da9fc2021b8a241967","value":148}},"10f157a48fbb42a3a2ac674dee40861d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62bee85c04254ee8b8ff04f4a2e06a9a","placeholder":"","style":"IPY_MODEL_3e922a6884114aba95f40a7ac5158d2b","value":" 148/300 [2:50:59&lt;2:55:32, 69.29s/it]"}},"4c823dbdde1c461d9489c2b04956c2f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac7cd2ac36c048d5b38dd1a4fe66aa3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"060caeb4ac0f4008907170511c40bc33":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bcb6e5a626e8419cb4002e1007b02454":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8943160977e443da9fc2021b8a241967":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"62bee85c04254ee8b8ff04f4a2e06a9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e922a6884114aba95f40a7ac5158d2b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dbd7225d3665454abef8f4b213b2352c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f8d901df0514228a3dc7b9b18419fa1","IPY_MODEL_daccf5f6a00248b4ab162a43bf80690d","IPY_MODEL_23198c5f195a43dd97f2c61796d070fc"],"layout":"IPY_MODEL_891aa2de400b411f8841c6cee9ebbf77"}},"2f8d901df0514228a3dc7b9b18419fa1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c861137acf643e293d8f5136ddd7d31","placeholder":"","style":"IPY_MODEL_8b830d7a63bf402aa9128cefc911b95f","value":" 50%"}},"daccf5f6a00248b4ab162a43bf80690d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_59751320e92643918df6ad82903db137","max":200,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84a9700af9b949a3a7393492a317959f","value":101}},"23198c5f195a43dd97f2c61796d070fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b6093fe4c714c4bbcc4ac6c2607169d","placeholder":"","style":"IPY_MODEL_a7baf7cb3640477cb68f404c98160910","value":" 101/200 [1:55:09&lt;1:52:12, 68.01s/it]"}},"891aa2de400b411f8841c6cee9ebbf77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c861137acf643e293d8f5136ddd7d31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b830d7a63bf402aa9128cefc911b95f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59751320e92643918df6ad82903db137":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84a9700af9b949a3a7393492a317959f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b6093fe4c714c4bbcc4ac6c2607169d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7baf7cb3640477cb68f404c98160910":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}